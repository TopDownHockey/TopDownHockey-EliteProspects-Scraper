{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "proof-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4  import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import json\n",
    "from json import loads, dumps\n",
    "import lxml\n",
    "from requests import ConnectionError, ReadTimeout, ConnectTimeout, HTTPError, Timeout\n",
    "import xml\n",
    "import re\n",
    "from natsort import natsorted\n",
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict\n",
    "from xml.parsers.expat import ExpatError\n",
    "ewc = ['SHOT', 'HIT', 'BLOCK', 'MISS', 'GIVE', 'TAKE', 'GOAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-terrorist",
   "metadata": {},
   "source": [
    "# SCRAPE API SCHEDULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "brutal-mailing",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape_schedule(start_date, end_date):\n",
    "    url = 'https://statsapi.web.nhl.com/api/v1/schedule?startDate=' + start_date + '&endDate=' + end_date\n",
    "    page = requests.get(url, timeout = 500)\n",
    "    loaddict = json.loads(page.content)\n",
    "    date_list = (loaddict['dates'])\n",
    "    date_df = pd.DataFrame(date_list)\n",
    "    \n",
    "    gamedf = pd.DataFrame()\n",
    "\n",
    "    for i in range (0, len(date_df)):\n",
    "        datedf = pd.DataFrame(date_df.games.iloc[i])\n",
    "        gamedf = gamedf.append(datedf)\n",
    "    global team_df\n",
    "    team_df = pd.DataFrame(gamedf['teams'].values.tolist(), index = gamedf.index)\n",
    "    away_df = pd.DataFrame(team_df['away'].values.tolist(), index = team_df.index)\n",
    "    home_df = pd.DataFrame(team_df['home'].values.tolist(), index = team_df.index)\n",
    "    away_team_df = pd.DataFrame(away_df['team'].values.tolist(), index = away_df.index)\n",
    "    home_team_df = pd.DataFrame(home_df['team'].values.tolist(), index = home_df.index)\n",
    "\n",
    "    gamedf = gamedf.assign(\n",
    "        state = pd.DataFrame(gamedf['status'].values.tolist(), index = gamedf.index)['detailedState'],\n",
    "        homename = home_team_df['name'],\n",
    "        homeid = home_team_df['id'],\n",
    "        homescore = home_df['score'],\n",
    "        awayname = away_team_df['name'],\n",
    "        awayid = away_team_df['id'],\n",
    "        awayscore = away_df['score'],\n",
    "        venue = pd.DataFrame(gamedf['venue'].values.tolist(), index = gamedf.index)['name'],\n",
    "        gameDate = pd.to_datetime(gamedf['gameDate']).dt.tz_convert('EST')\n",
    "    )\n",
    "\n",
    "    gamedf = gamedf.loc[:, ['gamePk', 'link', 'gameType', 'season', 'gameDate','homeid', 'homename',  'homescore','awayid', 'awayname',  'awayscore', 'state', 'venue']].rename(\n",
    "        columns = {'gamePk':'ID', 'gameType':'type', 'gameDate':'date'})\n",
    "\n",
    "    return gamedf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-parts",
   "metadata": {},
   "source": [
    "# Harry's Strip HTML Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "informal-freeze",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hs_strip_html(td):\n",
    "    \"\"\"\n",
    "    Function from Harry Shomer's Github\n",
    "    \n",
    "    Strip html tags and such \n",
    "    \n",
    "    :param td: pbp\n",
    "    \n",
    "    :return: list of plays (which contain a list of info) stripped of html\n",
    "    \"\"\"\n",
    "    for y in range(len(td)):\n",
    "        # Get the 'br' tag for the time column...this get's us time remaining instead of elapsed and remaining combined\n",
    "        if y == 3:\n",
    "            td[y] = td[y].get_text()   # This gets us elapsed and remaining combined-< 3:0017:00\n",
    "            index = td[y].find(':')\n",
    "            td[y] = td[y][:index+3]\n",
    "        elif (y == 6 or y == 7) and td[0] != '#':\n",
    "            # 6 & 7-> These are the player 1 ice one's\n",
    "            # The second statement controls for when it's just a header\n",
    "            baz = td[y].find_all('td')\n",
    "            bar = [baz[z] for z in range(len(baz)) if z % 4 != 0]  # Because of previous step we get repeats...delete some\n",
    "\n",
    "            # The setup in the list is now: Name/Number->Position->Blank...and repeat\n",
    "            # Now strip all the html\n",
    "            players = []\n",
    "            for i in range(len(bar)):\n",
    "                if i % 3 == 0:\n",
    "                    try:\n",
    "                        name = return_name_html(bar[i].find('font')['title'])\n",
    "                        number = bar[i].get_text().strip('\\n')  # Get number and strip leading/trailing newlines\n",
    "                    except KeyError:\n",
    "                        name = ''\n",
    "                        number = ''\n",
    "                elif i % 3 == 1:\n",
    "                    if name != '':\n",
    "                        position = bar[i].get_text()\n",
    "                        players.append([name, number, position])\n",
    "\n",
    "            td[y] = players\n",
    "        else:\n",
    "            td[y] = td[y].get_text()\n",
    "\n",
    "    return td\n",
    "\n",
    "def group_if_not_none(result):\n",
    "    if result is not None:\n",
    "        result = result.group()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-roommate",
   "metadata": {},
   "source": [
    "# Scrape HTML Roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "primary-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_html_roster(season, game_id):\n",
    "    url = 'http://www.nhl.com/scores/htmlreports/' + season + '/RO0' + game_id + '.HTM'\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content.decode('ISO-8859-1'), 'lxml', multi_valued_attributes = None)\n",
    "    \n",
    "    teamsoup = soup.find_all('td', {'align':'center', 'class':['teamHeading + border', 'teamHeading + border '], 'width':'50%'})\n",
    "    away_team = teamsoup[0].get_text()\n",
    "    home_team = teamsoup[1].get_text()\n",
    "    \n",
    "    home_player_soup = (soup.find_all('table', {'align':'center', 'border':'0', 'cellpadding':'0', \n",
    "                        'cellspacing':'0', 'width':'100%', 'xmlns:ext':''}))[1].find_all('td')\n",
    "\n",
    "    length = int(len(home_player_soup)/3)\n",
    "\n",
    "    home_player_df = pd.DataFrame(np.array(home_player_soup).reshape(length, 3))\n",
    "\n",
    "    home_player_df.columns = home_player_df.iloc[0]\n",
    "\n",
    "    home_player_df = home_player_df.drop(0).assign(team = 'home', team_name = home_team)\n",
    "\n",
    "    away_player_soup = (soup.find_all('table', {'align':'center', 'border':'0', 'cellpadding':'0', \n",
    "                            'cellspacing':'0', 'width':'100%', 'xmlns:ext':''}))[0].find_all('td')\n",
    "\n",
    "    length = int(len(away_player_soup)/3)\n",
    "\n",
    "    away_player_df = pd.DataFrame(np.array(away_player_soup).reshape(length, 3))\n",
    "\n",
    "    away_player_df.columns = away_player_df.iloc[0]\n",
    "\n",
    "    away_player_df = away_player_df.drop(0).assign(team = 'away', team_name = away_team)\n",
    "    \n",
    "    #global home_scratch_soup\n",
    "    \n",
    "    if len(soup.find_all('table', {'align':'center', 'border':'0', 'cellpadding':'0', \n",
    "                            'cellspacing':'0', 'width':'100%', 'xmlns:ext':''}))>3:\n",
    "\n",
    "        home_scratch_soup = (soup.find_all('table', {'align':'center', 'border':'0', 'cellpadding':'0', \n",
    "                                'cellspacing':'0', 'width':'100%', 'xmlns:ext':''}))[3].find_all('td')\n",
    "    \n",
    "        if len(home_scratch_soup)>1:\n",
    "\n",
    "            length = int(len(home_scratch_soup)/3)\n",
    "\n",
    "            home_scratch_df = pd.DataFrame(np.array(home_scratch_soup).reshape(length, 3))\n",
    "\n",
    "            home_scratch_df.columns = home_scratch_df.iloc[0]\n",
    "\n",
    "            home_scratch_df = home_scratch_df.drop(0).assign(team = 'home', team_name = home_team)\n",
    "\n",
    "    if 'home_scratch_df' not in locals():\n",
    "        \n",
    "        home_scratch_df = pd.DataFrame()\n",
    "        \n",
    "    if len(soup.find_all('table', {'align':'center', 'border':'0', 'cellpadding':'0', \n",
    "                            'cellspacing':'0', 'width':'100%', 'xmlns:ext':''}))>2:\n",
    "    \n",
    "        away_scratch_soup = (soup.find_all('table', {'align':'center', 'border':'0', 'cellpadding':'0', \n",
    "                                'cellspacing':'0', 'width':'100%', 'xmlns:ext':''}))[2].find_all('td')\n",
    "        \n",
    "        if len(away_scratch_soup)>1:\n",
    "\n",
    "            length = int(len(away_scratch_soup)/3)\n",
    "\n",
    "            away_scratch_df = pd.DataFrame(np.array(away_scratch_soup).reshape(length, 3))\n",
    "\n",
    "            away_scratch_df.columns = away_scratch_df.iloc[0]\n",
    "\n",
    "            away_scratch_df = away_scratch_df.drop(0).assign(team = 'away', team_name = away_team)\n",
    "        \n",
    "    if 'away_scratch_df' not in locals():\n",
    "        \n",
    "        away_scratch_df = pd.DataFrame()\n",
    "\n",
    "    player_df = pd.concat([home_player_df, away_player_df]).assign(status = 'player')\n",
    "    scratch_df = pd.concat([home_scratch_df, away_scratch_df]).assign(status = 'scratch')\n",
    "    roster_df = pd.concat([player_df, scratch_df])\n",
    "    \n",
    "    roster_df = roster_df.assign(team = np.where(roster_df.team=='CANADIENS MONTREAL', 'MONTREAL CANADIENS', roster_df.team))\n",
    "    \n",
    "    # FIX NAMES\n",
    "\n",
    "    roster_df = roster_df.rename(columns = {'Nom/Name':'Name'})\n",
    "    \n",
    "    roster_df.Name = roster_df.Name.str.split('(').str[0].str.strip()\n",
    "    \n",
    "    # Max Pacioretty doesn't exist in ESPN in 2009-2010, sadly.\n",
    "    \n",
    "    roster_df['Name'] = np.where(roster_df['Name'].str.contains('ALEXANDRE '), \n",
    "                                roster_df.Name.str.replace('ALEXANDRE ', 'ALEX '),\n",
    "                                roster_df['Name'])\n",
    "    \n",
    "    roster_df['Name'] = np.where(roster_df['Name'].str.contains('ALEXANDER '), \n",
    "                                roster_df.Name.str.replace('ALEXANDER ', 'ALEX '),\n",
    "                                roster_df['Name'])\n",
    "    \n",
    "    roster_df['Name'] = np.where(roster_df['Name'].str.contains('CHRISTOPHER '), \n",
    "                                roster_df.Name.str.replace('CHRISTOPHER ', 'CHRIS '),\n",
    "                                roster_df['Name'])\n",
    "    \n",
    "    roster_df = roster_df.assign(Name = \n",
    "    (np.where(roster_df['Name']== \"ANDREI KASTSITSYN\" , \"ANDREI KOSTITSYN\",\n",
    "    (np.where(roster_df['Name']== \"AJ GREER\" , \"A.J.  GREER\",\n",
    "    (np.where(roster_df['Name']== \"ANDREW GREENE\" , \"ANDY GREENE\",\n",
    "    (np.where(roster_df['Name']== \"ANDREW WOZNIEWSKI\" , \"ANDY WOZNIEWSKI\", \n",
    "    (np.where(roster_df['Name']== \"ANTHONY DEANGELO\" , \"TONY DEANGELO\",\n",
    "    (np.where(roster_df['Name']== \"BATES (JON) BATTAGLIA\" , \"BATES BATTAGLIA\",\n",
    "    (np.where(roster_df['Name'].isin([\"BJ CROMBEEN\", \"B.J. CROMBEEN\", \"BRANDON CROMBEEN\", \"B J CROMBEEN\"]) , \"B.J. CROMBEEN\", \n",
    "    (np.where(roster_df['Name']== \"BRADLEY MILLS\" , \"BRAD MILLS\",\n",
    "    (np.where(roster_df['Name']== \"CAMERON BARKER\" , \"CAM BARKER\", \n",
    "    (np.where(roster_df['Name']== \"COLIN (JOHN) WHITE\" , \"COLIN WHITE\",\n",
    "    (np.where(roster_df['Name']== \"CRISTOVAL NIEVES\" , \"BOO NIEVES\",\n",
    "    (np.where(roster_df['Name']== \"CHRIS VANDE VELDE\" , \"CHRIS VANDEVELDE\", \n",
    "    (np.where(roster_df['Name']== \"DANNY BRIERE\" , \"DANIEL BRIERE\",\n",
    "    (np.where(roster_df['Name'].isin([\"DAN CLEARY\", \"DANNY CLEARY\"]) , \"DANIEL CLEARY\",\n",
    "    (np.where(roster_df['Name']== \"DANIEL GIRARDI\" , \"DAN GIRARDI\", \n",
    "    (np.where(roster_df['Name']== \"DANNY O'REGAN\" , \"DANIEL O'REGAN\",\n",
    "    (np.where(roster_df['Name']== \"DANIEL CARCILLO\" , \"DAN CARCILLO\", \n",
    "    (np.where(roster_df['Name']== \"DAVID JOHNNY ODUYA\" , \"JOHNNY ODUYA\", \n",
    "    (np.where(roster_df['Name']== \"DAVID BOLLAND\" , \"DAVE BOLLAND\", \n",
    "    (np.where(roster_df['Name']== \"DENIS JR  GAUTHIER\" , \"DENIS GAUTHIER\",\n",
    "    (np.where(roster_df['Name']== \"DWAYNE KING\" , \"DJ KING\", \n",
    "    (np.where(roster_df['Name']== \"EDWARD PURCELL\" , \"TEDDY PURCELL\", \n",
    "    (np.where(roster_df['Name']== \"EMMANUEL FERNANDEZ\" , \"MANNY FERNANDEZ\", \n",
    "    (np.where(roster_df['Name']== \"EMMANUEL LEGACE\" , \"MANNY LEGACE\", \n",
    "    (np.where(roster_df['Name']== \"EVGENII DADONOV\" , \"EVGENY DADONOV\", \n",
    "    (np.where(roster_df['Name']== \"FREDDY MODIN\" , \"FREDRIK MODIN\", \n",
    "    (np.where(roster_df['Name']== \"FREDERICK MEYER IV\" , \"FREDDY MEYER\",\n",
    "    (np.where(roster_df['Name']== \"HARRISON ZOLNIERCZYK\" , \"HARRY ZOLNIERCZYK\", \n",
    "    (np.where(roster_df['Name']== \"ILJA BRYZGALOV\" , \"ILYA BRYZGALOV\", \n",
    "    (np.where(roster_df['Name']== \"JACOB DOWELL\" , \"JAKE DOWELL\",\n",
    "    (np.where(roster_df['Name']== \"JAMES HOWARD\" , \"JIMMY HOWARD\", \n",
    "    (np.where(roster_df['Name']== \"JAMES VANDERMEER\" , \"JIM VANDERMEER\",\n",
    "    (np.where(roster_df['Name']== \"JAMES WYMAN\" , \"JT WYMAN\",\n",
    "    (np.where(roster_df['Name']== \"JOHN HILLEN III\" , \"JACK HILLEN\",\n",
    "    (np.where(roster_df['Name']== \"JOHN ODUYA\" , \"JOHNNY ODUYA\",\n",
    "    (np.where(roster_df['Name']== \"JOHN PEVERLEY\" , \"RICH PEVERLEY\",\n",
    "    (np.where(roster_df['Name']== \"JONATHAN SIM\" , \"JON SIM\",\n",
    "    (np.where(roster_df['Name']== \"JONATHON KALINSKI\" , \"JON KALINSKI\",\n",
    "    (np.where(roster_df['Name']== \"JONATHAN AUDY-MARCHESSAULT\" , \"JONATHAN MARCHESSAULT\", \n",
    "    (np.where(roster_df['Name']== \"JOSEPH CRABB\" , \"JOEY CRABB\",\n",
    "    (np.where(roster_df['Name']== \"JOSEPH CORVO\" , \"JOE CORVO\", \n",
    "    (np.where(roster_df['Name']== \"JOSHUA BAILEY\" , \"JOSH BAILEY\",\n",
    "    (np.where(roster_df['Name']== \"JOSHUA HENNESSY\" , \"JOSH HENNESSY\", \n",
    "    (np.where(roster_df['Name']== \"JOSHUA MORRISSEY\" , \"JOSH MORRISSEY\",\n",
    "    (np.where(roster_df['Name']== \"JEAN-FRANCOIS JACQUES\" , \"J-F JACQUES\", \n",
    "    (np.where(roster_df['Name'].isin([\"J P DUMONT\", \"JEAN-PIERRE DUMONT\"]) , \"J-P DUMONT\", \n",
    "    (np.where(roster_df['Name']== \"JT COMPHER\" , \"J.T. COMPHER\",\n",
    "    (np.where(roster_df['Name']== \"KRISTOPHER LETANG\" , \"KRIS LETANG\", \n",
    "    (np.where(roster_df['Name']== \"KRYSTOFER BARCH\" , \"KRYS BARCH\", \n",
    "    (np.where(roster_df['Name']== \"KRYSTOFER KOLANOS\" , \"KRYS KOLANOS\",\n",
    "    (np.where(roster_df['Name']== \"MARC POULIOT\" , \"MARC-ANTOINE POULIOT\",\n",
    "    (np.where(roster_df['Name']== \"MARTIN ST LOUIS\" , \"MARTIN ST. LOUIS\", \n",
    "    (np.where(roster_df['Name']== \"MARTIN ST PIERRE\" , \"MARTIN ST. PIERRE\",\n",
    "    (np.where(roster_df['Name']== \"MARTY HAVLAT\" , \"MARTIN HAVLAT\",\n",
    "    (np.where(roster_df['Name']== \"MATTHEW CARLE\" , \"MATT CARLE\", \n",
    "    (np.where(roster_df['Name']== \"MATHEW DUMBA\" , \"MATT DUMBA\",\n",
    "    (np.where(roster_df['Name']== \"MATTHEW BENNING\" , \"MATT BENNING\", \n",
    "    (np.where(roster_df['Name']== \"MATTHEW IRWIN\" , \"MATT IRWIN\",\n",
    "    (np.where(roster_df['Name']== \"MATTHEW NIETO\" , \"MATT NIETO\",\n",
    "    (np.where(roster_df['Name']== \"MATTHEW STAJAN\" , \"MATT STAJAN\",\n",
    "    (np.where(roster_df['Name']== \"MAXIM MAYOROV\" , \"MAKSIM MAYOROV\",\n",
    "    (np.where(roster_df['Name']== \"MAXIME TALBOT\" , \"MAX TALBOT\", \n",
    "    (np.where(roster_df['Name']== \"MAXWELL REINHART\" , \"MAX REINHART\",\n",
    "    (np.where(roster_df['Name']== \"MICHAEL BLUNDEN\" , \"MIKE BLUNDEN\",\n",
    "    (np.where(roster_df['Name']== \"MICHAËL BOURNIVAL\" , \"MICHAEL BOURNIVAL\",\n",
    "    (np.where(roster_df['Name']== \"MICHAEL CAMMALLERI\" , \"MIKE CAMMALLERI\", \n",
    "    (np.where(roster_df['Name']== \"MICHAEL FERLAND\" , \"MICHEAL FERLAND\", \n",
    "    (np.where(roster_df['Name']== \"MICHAEL GRIER\" , \"MIKE GRIER\",\n",
    "    (np.where(roster_df['Name']== \"MICHAEL KNUBLE\" , \"MIKE KNUBLE\",\n",
    "    (np.where(roster_df['Name']== \"MICHAEL KOMISAREK\" , \"MIKE KOMISAREK\",\n",
    "    (np.where(roster_df['Name']== \"MICHAEL MATHESON\" , \"MIKE MATHESON\",\n",
    "    (np.where(roster_df['Name']== \"MICHAEL MODANO\" , \"MIKE MODANO\",\n",
    "    (np.where(roster_df['Name']== \"MICHAEL RUPP\" , \"MIKE RUPP\",\n",
    "    (np.where(roster_df['Name']== \"MICHAEL SANTORELLI\" , \"MIKE SANTORELLI\", \n",
    "    (np.where(roster_df['Name']== \"MICHAEL SILLINGER\" , \"MIKE SILLINGER\",\n",
    "    (np.where(roster_df['Name']== \"MITCHELL MARNER\" , \"MITCH MARNER\", \n",
    "    (np.where(roster_df['Name']== \"NATHAN GUENIN\" , \"NATE GUENIN\",\n",
    "    (np.where(roster_df['Name']== \"NICHOLAS BOYNTON\" , \"NICK BOYNTON\",\n",
    "    (np.where(roster_df['Name']== \"NICHOLAS DRAZENOVIC\" , \"NICK DRAZENOVIC\", \n",
    "    (np.where(roster_df['Name']== \"NICKLAS BERGFORS\" , \"NICLAS BERGFORS\",\n",
    "    (np.where(roster_df['Name']== \"NICKLAS GROSSMAN\" , \"NICKLAS GROSSMANN\", \n",
    "    (np.where(roster_df['Name']== \"NICOLAS PETAN\" , \"NIC PETAN\", \n",
    "    (np.where(roster_df['Name']== \"NIKLAS KRONVALL\" , \"NIKLAS KRONWALL\",\n",
    "    (np.where(roster_df['Name']== \"NIKOLAI ANTROPOV\" , \"NIK ANTROPOV\",\n",
    "    (np.where(roster_df['Name']== \"NIKOLAI KULEMIN\" , \"NIKOLAY KULEMIN\", \n",
    "    (np.where(roster_df['Name']== \"NIKOLAI ZHERDEV\" , \"NIKOLAY ZHERDEV\",\n",
    "    (np.where(roster_df['Name']== \"OLIVIER MAGNAN-GRENIER\" , \"OLIVIER MAGNAN\",\n",
    "    (np.where(roster_df['Name']== \"PAT MAROON\" , \"PATRICK MAROON\", \n",
    "    (np.where(roster_df['Name'].isin([\"P. J. AXELSSON\", \"PER JOHAN AXELSSON\"]) , \"P.J. AXELSSON\",\n",
    "    (np.where(roster_df['Name'].isin([\"PK SUBBAN\", \"P.K SUBBAN\"]) , \"P.K.  SUBBAN\", \n",
    "    (np.where(roster_df['Name'].isin([\"PIERRE PARENTEAU\", \"PIERRE-ALEX PARENTEAU\", \"PIERRE-ALEXANDRE PARENTEAU\", \"PA PARENTEAU\", \"P.A PARENTEAU\", \"P-A PARENTEAU\"]) , \"P A  PARENTEAU\", \n",
    "    (np.where(roster_df['Name']== \"PHILIP VARONE\" , \"PHIL VARONE\",\n",
    "    (np.where(roster_df['Name']== \"QUINTIN HUGHES\" , \"QUINN HUGHES\",\n",
    "    (np.where(roster_df['Name']== \"RAYMOND MACIAS\" , \"RAY MACIAS\",\n",
    "    (np.where(roster_df['Name']== \"RJ UMBERGER\" , \"R.J. UMBERGER\",\n",
    "    (np.where(roster_df['Name']== \"ROBERT BLAKE\" , \"ROB BLAKE\",\n",
    "    (np.where(roster_df['Name']== \"ROBERT EARL\" , \"ROBBIE EARL\",\n",
    "    (np.where(roster_df['Name']== \"ROBERT HOLIK\" , \"BOBBY HOLIK\",\n",
    "    (np.where(roster_df['Name']== \"ROBERT SCUDERI\" , \"ROB SCUDERI\",\n",
    "    roster_df['Name']))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
    "    )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
    "    ))))))))))\n",
    "    \n",
    "    roster_df['Name'] = (np.where(roster_df['Name']== \"RODNEY PELLEY\" , \"ROD PELLEY\",\n",
    "    (np.where(roster_df['Name']== \"SIARHEI KASTSITSYN\" , \"SERGEI KOSTITSYN\",\n",
    "    (np.where(roster_df['Name']== \"SIMEON VARLAMOV\" , \"SEMYON VARLAMOV\", \n",
    "    (np.where(roster_df['Name']== \"STAFFAN KRONVALL\" , \"STAFFAN KRONWALL\",\n",
    "    (np.where(roster_df['Name']== \"STEVEN REINPRECHT\" , \"STEVE REINPRECHT\",\n",
    "    (np.where(roster_df['Name']== \"TJ GALIARDI\" , \"T.J. GALIARDI\",\n",
    "    (np.where(roster_df['Name']== \"TJ HENSICK\" , \"T.J  HENSICK\",\n",
    "    (np.where(roster_df['Name'].isin([\"TJ OSHIE\", \"T.J OSHIE\"]) , \"T.J. OSHIE\", \n",
    "    (np.where(roster_df['Name']== \"TOBY ENSTROM\" , \"TOBIAS ENSTROM\", \n",
    "    (np.where(roster_df['Name']== \"TOMMY SESTITO\" , \"TOM SESTITO\",\n",
    "    (np.where(roster_df['Name']== \"VACLAV PROSPAL\" , \"VINNY PROSPAL\",\n",
    "    (np.where(roster_df['Name']== \"VINCENT HINOSTROZA\" , \"VINNIE HINOSTROZA\",\n",
    "    (np.where(roster_df['Name']== \"WILLIAM THOMAS\" , \"BILL THOMAS\",\n",
    "    (np.where(roster_df['Name']== \"ZACHARY ASTON-REESE\" , \"ZACH ASTON-REESE\",\n",
    "    (np.where(roster_df['Name']== \"ZACHARY SANFORD\" , \"ZACH SANFORD\",\n",
    "    (np.where(roster_df['Name']== \"ZACHERY STORTINI\" , \"ZACK STORTINI\",\n",
    "    (np.where(roster_df['Name']== \"MATTHEW MURRAY\" , \"MATT MURRAY\",\n",
    "    (np.where(roster_df['Name']== \"J-SEBASTIEN AUBIN\" , \"JEAN-SEBASTIEN AUBIN\",\n",
    "    (np.where(roster_df['Name'].isin([\"J.F.  BERUBE\", \"JEAN-FRANCOIS BERUBE\"]) , \"J-F BERUBE\", \n",
    "    (np.where(roster_df['Name']== \"JEFF DROUIN-DESLAURIERS\" , \"JEFF DESLAURIERS\", \n",
    "    (np.where(roster_df['Name']== \"NICHOLAS BAPTISTE\" , \"NICK BAPTISTE\",\n",
    "    (np.where(roster_df['Name']== \"OLAF KOLZIG\" , \"OLIE KOLZIG\",\n",
    "    (np.where(roster_df['Name']== \"STEPHEN VALIQUETTE\" , \"STEVE VALIQUETTE\",\n",
    "    (np.where(roster_df['Name']== \"THOMAS MCCOLLUM\" , \"TOM MCCOLLUM\",\n",
    "    (np.where(roster_df['Name']== \"TIMOTHY JR  THOMAS\" , \"TIM THOMAS\",\n",
    "    (np.where(roster_df['Name']== \"TIM GETTINGER\" , \"TIMOTHY GETTINGER\",\n",
    "    (np.where(roster_df['Name']== \"NICHOLAS SHORE\" , \"NICK SHORE\",\n",
    "    (np.where(roster_df['Name']== \"T.J  TYNAN\" , \"TJ TYNAN\",\n",
    "    (np.where(roster_df['Name']== \"ALEXIS LAFRENI?RE\" , \"ALEXIS LAFRENIÈRE\",\n",
    "    (np.where(roster_df['Name']== \"ALEXIS LAFRENIERE\" , \"ALEXIS LAFRENIÈRE\", \n",
    "    (np.where(roster_df['Name']== \"ALEXIS LAFRENIÃRE\" , \"ALEXIS LAFRENIÈRE\",\n",
    "    (np.where(roster_df['Name']== \"TIM STUTZLE\" , \"TIM STÜTZLE\",\n",
    "    (np.where(roster_df['Name']== \"TIM ST?TZLE\" , \"TIM STÜTZLE\",\n",
    "    (np.where(roster_df['Name']== \"TIM STÃTZLE\" , \"TIM STÜTZLE\",\n",
    "    (np.where(roster_df['Name']== \"EGOR SHARANGOVICH\" , \"YEGOR SHARANGOVICH\",\n",
    "    (np.where(roster_df['Name']== \"CALLAN FOOTE\" , \"CAL FOOTE\",\n",
    "    (np.where(roster_df['Name']== \"MATTIAS JANMARK-NYLEN\" , \"MATTIAS JANMARK\",\n",
    "    (np.where(roster_df['Name']== \"JOSH DUNNE\" , \"JOSHUA DUNNE\",roster_df['Name'])))))))))))))))))))))))))))))))))))))))))))\n",
    "    )))))))))))))))))))))))))))))))))\n",
    "\n",
    "    return roster_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-mortality",
   "metadata": {},
   "source": [
    "# SCRAPE HTML SHIFTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "genetic-money",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape_html_shifts(season, game_id):\n",
    "    \n",
    "    url = 'http://www.nhl.com/scores/htmlreports/' + season + '/TH0' + game_id + '.HTM'\n",
    "    page = (requests.get(url))\n",
    "    soup = BeautifulSoup(page.content.decode('ISO-8859-1'), 'lxml', multi_valued_attributes = None)\n",
    "    found = soup.find_all('td', {'class':['playerHeading + border', 'lborder + bborder']})\n",
    "    if len(found)==0:\n",
    "        raise IndexError('This game has no shift data.')\n",
    "    thisteam = soup.find('td', {'align':'center', 'class':'teamHeading + border'}).get_text()\n",
    "\n",
    "    players = dict()\n",
    "\n",
    "    for i in range(len(found)):\n",
    "        line = found[i].get_text()\n",
    "        if ', ' in line:\n",
    "            name = line.split(',')\n",
    "            number = name[0].split(' ')[0].strip()\n",
    "            last_name =  name[0].split(' ')[1].strip()\n",
    "            first_name = name[1].strip()\n",
    "            full_name = first_name + \" \" + last_name\n",
    "            players[full_name] = dict()\n",
    "            players[full_name]['number'] = number\n",
    "            players[full_name]['name'] = full_name\n",
    "            players[full_name]['shifts'] = []\n",
    "        else:\n",
    "            players[full_name]['shifts'].extend([line])\n",
    "\n",
    "    alldf = pd.DataFrame()\n",
    "\n",
    "    for key in players.keys(): \n",
    "        length = int(len(np.array((players[key]['shifts'])))/5)\n",
    "        df = pd.DataFrame(np.array((players[key]['shifts'])).reshape(length, 5)).rename(\n",
    "        columns = {0:'shift_number', 1:'period', 2:'shift_start', 3:'shift_end', 4:'duration'})\n",
    "        df = df.assign(name = players[key]['name'],\n",
    "                      number = players[key]['number'],\n",
    "                      team = thisteam,\n",
    "                      venue = \"home\")\n",
    "        alldf = alldf.append(df)\n",
    "        \n",
    "    home_shifts = alldf\n",
    "    \n",
    "    url = 'http://www.nhl.com/scores/htmlreports/' + season + '/TV0' + game_id + '.HTM'\n",
    "    page = (requests.get(url))\n",
    "    soup = BeautifulSoup(page.content.decode('ISO-8859-1'), 'lxml', multi_valued_attributes = None)\n",
    "    found = soup.find_all('td', {'class':['playerHeading + border', 'lborder + bborder']})\n",
    "    thisteam = soup.find('td', {'align':'center', 'class':'teamHeading + border'}).get_text()\n",
    "\n",
    "    players = dict()\n",
    "\n",
    "    for i in range(len(found)):\n",
    "        line = found[i].get_text()\n",
    "        if ', ' in line:\n",
    "            name = line.split(',')\n",
    "            number = name[0].split(' ')[0].strip()\n",
    "            last_name =  name[0].split(' ')[1].strip()\n",
    "            first_name = name[1].strip()\n",
    "            full_name = first_name + \" \" + last_name\n",
    "            players[full_name] = dict()\n",
    "            players[full_name]['number'] = number\n",
    "            players[full_name]['name'] = full_name\n",
    "            players[full_name]['shifts'] = []\n",
    "        else:\n",
    "            players[full_name]['shifts'].extend([line])\n",
    "\n",
    "    alldf = pd.DataFrame()\n",
    "\n",
    "    for key in players.keys(): \n",
    "        length = int(len(np.array((players[key]['shifts'])))/5)\n",
    "        df = pd.DataFrame(np.array((players[key]['shifts'])).reshape(length, 5)).rename(\n",
    "        columns = {0:'shift_number', 1:'period', 2:'shift_start', 3:'shift_end', 4:'duration'})\n",
    "        df = df.assign(name = players[key]['name'],\n",
    "                      number = players[key]['number'],\n",
    "                      team = thisteam,\n",
    "                      venue = \"away\")\n",
    "        alldf = alldf.append(df)\n",
    "\n",
    "    away_shifts = alldf\n",
    "    \n",
    "    global all_shifts\n",
    "    \n",
    "    all_shifts = pd.concat([home_shifts, away_shifts])\n",
    "    \n",
    "    all_shifts = all_shifts.assign(start_time = all_shifts.shift_start.str.split('/').str[0])\n",
    "    \n",
    "    all_shifts = all_shifts.assign(end_time = all_shifts.shift_end.str.split('/').str[0])\n",
    "    \n",
    "    #all_shifts = all_shifts[~all_shifts.end_time.str.contains('\\xa0')]\n",
    "    \n",
    "    all_shifts.period = (np.where(all_shifts.period=='OT', 4, all_shifts.period)).astype(int)\n",
    "    \n",
    "    all_shifts = all_shifts.assign(end_time = np.where(~all_shifts.shift_end.str.contains('\\xa0'), all_shifts.end_time,\n",
    "              (np.where(\n",
    "              (((pd.to_datetime(((60 * (all_shifts.start_time.str.split(':').str[0].astype(int))) + \n",
    "              (all_shifts.start_time.str.split(':').str[1].astype(int)) + \n",
    "                (60 * (all_shifts.duration.str.split(':').str[0].astype(int))).astype(int) +\n",
    "              (all_shifts.duration.str.split(':').str[1].astype(int))).astype(int), unit = 's'))).dt.time).astype(str).str[3:].str[0]=='0',\n",
    "              (((pd.to_datetime(((60 * (all_shifts.start_time.str.split(':').str[0].astype(int))) + \n",
    "              (all_shifts.start_time.str.split(':').str[1].astype(int)) + \n",
    "                (60 * (all_shifts.duration.str.split(':').str[0].astype(int))).astype(int) +\n",
    "              (all_shifts.duration.str.split(':').str[1].astype(int))).astype(int), unit = 's'))).dt.time).astype(str).str[4:],\n",
    "              (((pd.to_datetime(((60 * (all_shifts.start_time.str.split(':').str[0].astype(int))) + \n",
    "              (all_shifts.start_time.str.split(':').str[1].astype(int)) + \n",
    "                (60 * (all_shifts.duration.str.split(':').str[0].astype(int))).astype(int) +\n",
    "              (all_shifts.duration.str.split(':').str[1].astype(int))).astype(int), unit = 's'))).dt.time).astype(str).str[4:]))))\n",
    "    \n",
    "    myshifts = all_shifts\n",
    "    \n",
    "    myshifts.start_time = myshifts.start_time.str.strip()\n",
    "    myshifts.end_time = myshifts.end_time.str.strip()\n",
    "    \n",
    "    changes_on = myshifts.groupby(['team', 'period', 'start_time']).agg(\n",
    "        on = ('name', ', '.join),\n",
    "        on_numbers = ('number', ', '.join),\n",
    "        number_on = ('name', 'count')\n",
    "    ).reset_index().rename(columns = {'start_time':'time'}).sort_values(by = ['team', 'period', 'time'])\n",
    "    \n",
    "    changes_off = myshifts.groupby(['team', 'period', 'end_time']).agg(\n",
    "        off = ('name', ', '.join),\n",
    "        off_numbers = ('number', ', '.join),\n",
    "        number_off = ('name', 'count')\n",
    "    ).reset_index().rename(columns = {'end_time':'time'}).sort_values(by = ['team', 'period', 'time'])\n",
    "    \n",
    "    all_on = changes_on.merge(changes_off, on = ['team', 'period', 'time'], how = 'left')\n",
    "    off_only = changes_off.merge(changes_on, on = ['team', 'period', 'time'], how = 'left', indicator = True)[\n",
    "    changes_off.merge(changes_on, on = ['team', 'period', 'time'], how = 'left', indicator = True)['_merge']!='both']\n",
    "    full_changes = pd.concat([all_on, off_only]).sort_values(by = ['period', 'time']).drop(columns = ['_merge'])\n",
    "    \n",
    "    full_changes['period_seconds'] = full_changes.time.str.split(':').str[0].astype(int) * 60 + full_changes.time.str.split(':').str[1].astype(int)\n",
    "\n",
    "    full_changes['game_seconds'] = (np.where(full_changes.period<5, \n",
    "                                   (((full_changes.period - 1) * 1200) + full_changes.period_seconds),\n",
    "                          3900))\n",
    "    \n",
    "    full_changes = full_changes.assign(team = np.where(full_changes.team=='CANADIENS MONTREAL', 'MONTREAL CANADIENS', full_changes.team))\n",
    "        \n",
    "    return full_changes.reset_index(drop = True)#.drop(columns = ['time', 'period_seconds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-testament",
   "metadata": {},
   "source": [
    "# Scrape API Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "saved-mineral",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape_api_events(game_id, drop_description = True, shift_to_espn = False):\n",
    "    \n",
    "    if shift_to_espn == True:\n",
    "        raise KeyError\n",
    "    \n",
    "    page = requests.get(str('https://statsapi.web.nhl.com/api/v1/game/' + str(game_id) + '/feed/live'))\n",
    "    \n",
    "    if str(page) == '<Response [404]>':\n",
    "        raise KeyError('You got the 404 error; game data could not be found.')\n",
    "    \n",
    "    loaddict = json.loads(page.content)\n",
    "    \n",
    "    if loaddict['liveData']['plays']['allPlays'] != []:\n",
    "    \n",
    "        eventdf = pd.DataFrame(loaddict['liveData']['plays']['allPlays'])\n",
    "\n",
    "        coordsdf = pd.DataFrame(eventdf['coordinates'].values.tolist(), index = eventdf.index)\n",
    "        resultdf = pd.DataFrame(eventdf['result'].values.tolist(), index = eventdf.index)\n",
    "        aboutdf = pd.DataFrame(eventdf['about'].values.tolist(), index = eventdf.index)\n",
    "        scoredf = pd.DataFrame(aboutdf['goals'].values.tolist(), index = aboutdf.index)\n",
    "        playerdf = pd.DataFrame(eventdf['players'])\n",
    "        teamdf = eventdf['team'].apply(pd.Series)\n",
    "        clean = playerdf[~pd.isna(playerdf.players)].reset_index()\n",
    "        clean_index = clean.loc[:, ['index']]\n",
    "        player1 = pd.DataFrame((pd.DataFrame(clean.reset_index()['players'].values.tolist())[0].values.tolist()))\n",
    "        player1df = pd.concat([clean_index, pd.DataFrame(player1['player'].values.tolist())], axis = 1).assign(playerType = player1['playerType']).rename(\n",
    "            columns = {'id':'player1id', 'fullName':'player1name', 'link':'player1link', 'playerType':'player1type'})\n",
    "        player2 = pd.concat([clean_index, pd.DataFrame((pd.DataFrame(clean['players'].values.tolist())[1]))], axis = 1)\n",
    "        player2 = player2[player2[1].notnull()]\n",
    "        player2df = pd.concat([player2.reset_index(drop = True), \n",
    "            (pd.DataFrame(pd.DataFrame(player2[1].values.tolist())['player'].values.tolist()).assign(playerType = (pd.DataFrame(player2[1].values.tolist())).loc[:, ['playerType']]))], axis = 1).drop(\n",
    "        columns = 1).rename(\n",
    "            columns = {'id':'player2id', 'fullName':'player2name', 'link':'player2link', 'playerType':'player2type'})\n",
    "\n",
    "        if len((pd.DataFrame(clean['players'].values.tolist())).columns) > 2:\n",
    "\n",
    "            player3 = pd.concat([clean_index, pd.DataFrame((pd.DataFrame(clean['players'].values.tolist())[2]))], axis = 1)\n",
    "            player3 = player3[player3[2].notnull()]\n",
    "            player3df = pd.concat([player3.reset_index(drop = True), \n",
    "                (pd.DataFrame(pd.DataFrame(player3[2].values.tolist())['player'].values.tolist()).assign(playerType = (pd.DataFrame(player3[2].values.tolist())).loc[:, ['playerType']]))], axis = 1).drop(\n",
    "            columns = 2).rename(\n",
    "                columns = {'id':'player3id', 'fullName':'player3name', 'link':'player3link', 'playerType':'player3type'})\n",
    "        else: \n",
    "            player3df = pd.DataFrame(columns = ['index', 'player3id', 'player3name', 'player3link', 'player3type'])\n",
    "\n",
    "        if len((pd.DataFrame(clean['players'].values.tolist())).columns) > 3:  \n",
    "\n",
    "            player4 = pd.concat([clean_index, pd.DataFrame((pd.DataFrame(clean['players'].values.tolist())[3]))], axis = 1)\n",
    "            player4 = player4[player4[3].notnull()]\n",
    "            player4df = pd.concat([player4.reset_index(drop = True), \n",
    "                (pd.DataFrame(pd.DataFrame(player4[3].values.tolist())['player'].values.tolist()).assign(playerType = (pd.DataFrame(player4[3].values.tolist())).loc[:, ['playerType']]))], axis = 1).drop(\n",
    "            columns = 3).rename(\n",
    "                columns = {'id':'player4id', 'fullName':'player4name', 'link':'player4link', 'playerType':'player4type'})\n",
    "        else: \n",
    "            player4df = pd.DataFrame(columns = ['index', 'player4id', 'player4name', 'player4link', 'player4type'])\n",
    "\n",
    "        finaldf = eventdf.assign(\n",
    "            hometeam = loaddict['gameData']['teams']['home']['triCode'],\n",
    "            hometeamfull = loaddict['gameData']['teams']['home']['name'],\n",
    "            awayteam = loaddict['gameData']['teams']['away']['triCode'],\n",
    "            awayteamfull = loaddict['gameData']['teams']['away']['name'],\n",
    "            description = resultdf['description'],\n",
    "            event = resultdf['eventTypeId'],\n",
    "            detail = resultdf['secondaryType'],\n",
    "            coords_x = coordsdf['x'],\n",
    "            coords_y = coordsdf['y'],\n",
    "            period = aboutdf['period'],\n",
    "            time = aboutdf['periodTime'],\n",
    "            homescore = scoredf['home'],\n",
    "            awayscore = scoredf['away'],\n",
    "            eventteam = teamdf['triCode'],\n",
    "            eventteamfull = teamdf['name'],\n",
    "            eventidx = aboutdf['eventIdx'],\n",
    "            eventNumber = aboutdf['eventId'],\n",
    "            session = loaddict['gameData']['game']['type'])\n",
    "\n",
    "        finaldf = finaldf.drop(columns = ['result', 'about', 'coordinates', 'players', 'team'])\n",
    "\n",
    "        finaldf = finaldf.reset_index().merge(\n",
    "        player1df, on = 'index', how = 'left').merge(\n",
    "        player2df, on = 'index', how = 'left').merge(\n",
    "        player3df, on = 'index', how = 'left').merge(\n",
    "        player4df, on = 'index', how = 'left')\n",
    "        \n",
    "        finaldf = finaldf.assign(\n",
    "            awayteamfull = finaldf.awayteamfull.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8'),\n",
    "            hometeamfull = finaldf.hometeamfull.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8'),\n",
    "            eventteamfull = finaldf.eventteamfull.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8'))\n",
    "        \n",
    "        finaldf = finaldf.assign(\n",
    "            player1name = np.where((finaldf.player1name=='Sebastian Aho') & (finaldf.eventteam=='NYI'),\n",
    "                     'Sebastian Aho (SWE)',\n",
    "                     finaldf.player1name\n",
    "                    ))\n",
    "\n",
    "        api_events = finaldf\n",
    "    \n",
    "        api_events.period = api_events.period.astype(int)\n",
    "        api_events.time = api_events.time.astype(str)\n",
    "\n",
    "        api_events.event = np.where(api_events.event=='BLOCKED_SHOT', 'BLOCK',\n",
    "        np.where(api_events.event=='BLOCKEDSHOT', 'BLOCK',\n",
    "                np.where(api_events.event=='MISSED_SHOT', 'MISS',\n",
    "                        np.where(api_events.event=='FACEOFF', 'FAC',\n",
    "                                np.where(api_events.event=='PENALTY', 'PENL',\n",
    "                                        np.where(api_events.event=='GIVEAWAY', 'GIVE',\n",
    "                                                np.where(api_events.event=='TAKEAWAY', 'TAKE',\n",
    "                                                         np.where(api_events.event=='MISSEDSHOT', 'MISS',\n",
    "                                                                  api_events.event))))))))\n",
    "\n",
    "        api_events = api_events[api_events.event.isin(['TAKE', 'GIVE', 'MISS', 'HIT', 'SHOT', 'BLOCK', 'GOAL', 'PENL', 'FAC'])]\n",
    "\n",
    "        api_events['awayteamfull'] = (api_events.awayteamfull.str.upper())\n",
    "        api_events['hometeamfull'] = (api_events.hometeamfull.str.upper())\n",
    "        api_events['eventteamfull'] = (api_events.eventteamfull.str.upper())\n",
    "\n",
    "        api_events['period_seconds'] = api_events.time.str.split(':').str[0].astype(int) * 60 + api_events.time.str.split(':').str[1].astype(int)\n",
    "\n",
    "        api_events['game_seconds'] = (np.where(api_events.period<5, \n",
    "                                       (((api_events.period - 1) * 1200) + api_events.period_seconds),\n",
    "                              3900))\n",
    "\n",
    "\n",
    "        api_events = api_events.loc[:, ['period_seconds', 'game_seconds', 'event', 'session', 'coords_x', 'coords_y', 'description', 'period',\n",
    "                                        'eventteam', 'eventteamfull', 'hometeamfull', 'awayteamfull', 'player1name', 'player2name', 'player3name', 'player4name']].rename(\n",
    "            columns = {'eventteamfull':'event_team'})\n",
    "\n",
    "        api_events = api_events.assign(\n",
    "        player1name = api_events.player1name.str.upper(),\n",
    "        player2name = api_events.player2name.str.upper(),\n",
    "        player3name = api_events.player3name.str.upper()\n",
    "        ).drop(columns = 'player4name').rename(columns = {'player1name':'ep1_name', 'player2name':'ep2_name', 'player3name':'ep3_name'})\n",
    "    \n",
    "        api_events = api_events.assign(event_team = np.where(api_events.event!='BLOCK', api_events.event_team,\n",
    "            np.where(api_events.event_team==api_events.hometeamfull, api_events.awayteamfull, api_events.hometeamfull)))\n",
    "        \n",
    "        api_events = api_events.assign(ep1_name = np.where(api_events.event!='BLOCK', api_events.ep1_name, api_events.ep2_name))\n",
    "    \n",
    "        api_events = api_events.sort_values(by = ['game_seconds', 'event_team', 'ep1_name'])\n",
    "    \n",
    "        api_events = api_events.assign(version = \n",
    "                               (np.where(\n",
    "                               (api_events.event==api_events.event.shift()) & \n",
    "                               (api_events.ep1_name==api_events.ep1_name.shift()) &\n",
    "                               (api_events.game_seconds==api_events.game_seconds.shift()),\n",
    "                                1, 0)))\n",
    "\n",
    "        api_events = api_events.assign(version = \n",
    "                               (np.where(\n",
    "                               (api_events.event==api_events.event.shift(2)) & \n",
    "                               (api_events.ep1_name==api_events.ep1_name.shift(2)) &\n",
    "                               (api_events.game_seconds==api_events.game_seconds.shift(2) )& \n",
    "                               (~api_events.description.str.contains('Penalty Shot')),\n",
    "                                2, api_events.version)))\n",
    "\n",
    "        api_events = api_events.assign(version = \n",
    "                               (np.where(\n",
    "                               (api_events.event==api_events.event.shift(3)) & \n",
    "                               (api_events.ep1_name==api_events.ep1_name.shift(3)) &\n",
    "                               (api_events.game_seconds==api_events.game_seconds.shift(3)),\n",
    "                                3, api_events.version)))#.drop(columns = 'description')\n",
    "        \n",
    "        api_events['ep1_name'] = np.where((api_events.description.str.contains('Too many men')) | (api_events.description.str.contains('unsportsmanlike conduct-bench')), 'BENCH', api_events['ep1_name'])\n",
    "        \n",
    "        api_events['ep1_name'] = np.where(api_events['ep1_name'].str.contains('ALEXANDRE '), \n",
    "                                api_events['ep1_name'].str.replace('ALEXANDRE ', 'ALEX '),\n",
    "                                api_events['ep1_name'])\n",
    "    \n",
    "        api_events['ep1_name'] = np.where(api_events['ep1_name'].str.contains('ALEXANDER '), \n",
    "                                    api_events['ep1_name'].str.replace('ALEXANDER ', 'ALEX '),\n",
    "                                    api_events['ep1_name'])\n",
    "\n",
    "        api_events['ep1_name'] = np.where(api_events['ep1_name'].str.contains('CHRISTOPHER '), \n",
    "                                    api_events['ep1_name'].str.replace('CHRISTOPHER ', 'CHRIS '),\n",
    "                                    api_events['ep1_name'])\n",
    "        \n",
    "        api_events = api_events.assign(\n",
    "        ep1_name = \n",
    "        (np.where(api_events['ep1_name']==\"ALEX PECHURSKIY\", \"ALEX PECHURSKI\", \n",
    "        (np.where(api_events['ep1_name']==\"BEN ONDRUS\", \"BENJAMIN ONDRUS\", \n",
    "        (np.where(api_events['ep1_name']==\"BRYCE VAN BRABANT\", \"BRYCE VAN BRABANT\", \n",
    "        (np.where(api_events['ep1_name']==\"CALVIN DE HAAN\", \"CALVIN DE HAAN\", \n",
    "        (np.where(api_events['ep1_name']==\"CHASE DE LEO\", \"CHASE DE LEO\", \n",
    "        (np.where(api_events['ep1_name']==\"CAL PETERSEN\", \"CALVIN PETERSEN\",\n",
    "        (np.where(api_events['ep1_name']==\"DANIEL CARCILLO\", \"DAN CARCILLO\", \n",
    "        (np.where(api_events['ep1_name']==\"DANNY O'REGAN\", \"DANIEL O'REGAN\", \n",
    "        (np.where(api_events['ep1_name']==\"DAVID VAN DER GULIK\", \"DAVID VAN DER GULIK\", \n",
    "        (np.where(api_events['ep1_name']==\"EVGENII DADONOV\", \"EVGENY DADONOV\", \n",
    "        (np.where(api_events['ep1_name']==\"FREDDY MODIN\", \"FREDRIK MODIN\", \n",
    "        (np.where(api_events['ep1_name']==\"GREG DE VRIES\", \"GREG DE VRIES\", \n",
    "        (np.where(api_events['ep1_name']==\"ILYA ZUBOV\", \"ILJA ZUBOV\", \n",
    "        (np.where(api_events['ep1_name']==\"JACOB DE LA ROSE\", \"JACOB DE LA ROSE\", \n",
    "        (np.where(api_events['ep1_name']==\"JAMES VAN RIEMSDYK\", \"JAMES VAN RIEMSDYK\", \n",
    "        (np.where(api_events['ep1_name']==\"JEAN-FRANCOIS JACQUES\", \"J-F JACQUES\", \n",
    "        (np.where(api_events['ep1_name']==\"JAKOB FORSBACKA KARLSSON\", \"JAKOB FORSBACKA KARLSSON\", \n",
    "        (np.where(api_events['ep1_name']==\"JIM DOWD\", \"JAMES DOWD\", \n",
    "        (np.where(api_events['ep1_name']==\"JEFF HAMILTON\", \"JEFFREY HAMILTON\", \n",
    "        (np.where(api_events['ep1_name']==\"JEFF PENNER\", \"JEFFREY PENNER\", \n",
    "        (np.where(api_events['ep1_name']==\"JOEL ERIKSSON EK\", \"JOEL ERIKSSON EK\", \n",
    "        (np.where(api_events['ep1_name']==\"MARK VAN GUILDER\", \"MARK VAN GUILDER\", \n",
    "        (np.where(api_events['ep1_name']==\"MARTIN ST LOUIS\", \"MARTIN ST. LOUIS\", \n",
    "        (np.where(api_events['ep1_name']==\"MARTIN ST PIERRE\", \"MARTIN ST. PIERRE\", \n",
    "        (np.where(api_events['ep1_name']==\"MARTIN ST PIERRE\", \"MARTIN ST. PIERRE\", \n",
    "        (np.where(api_events['ep1_name']==\"MICHAEL CAMMALLERI\", \"MIKE CAMMALLERI\", \n",
    "        (np.where(api_events['ep1_name']==\"MICHAEL DAL COLLE\", \"MICHAEL DAL COLLE\", \n",
    "        (np.where(api_events['ep1_name']==\"MICHAEL DEL ZOTTO\", \"MICHAEL DEL ZOTTO\", \n",
    "        (np.where(api_events['ep1_name']==\"MIKE VERNACE\", \"MICHAEL VERNACE\", \n",
    "        (np.where(api_events['ep1_name']==\"MIKE YORK\", \"MICHAEL YORK\", \n",
    "        (np.where(api_events['ep1_name']==\"MIKE VAN RYN\", \"MIKE VAN RYN\", \n",
    "        (np.where(api_events['ep1_name']==\"MITCHELL MARNER\", \"MITCH MARNER\", \n",
    "        (np.where(api_events['ep1_name']==\"PAT MAROON\", \"PATRICK MAROON\", \n",
    "        (np.where(api_events['ep1_name']==\"PA PARENTEAU\", \"P.A. PARENTEAU\", \n",
    "        (np.where(api_events['ep1_name']==\"PHILLIP DI GIUSEPPE\", \"PHILLIP DI GIUSEPPE\", \n",
    "        (np.where(api_events['ep1_name']==\"STEFAN DELLA ROVERE\", \"STEFAN DELLA ROVERE\", \n",
    "        (np.where(api_events['ep1_name']==\"STEPHANE DA COSTA\", \"STEPHANE DA COSTA\", \n",
    "        (np.where(api_events['ep1_name']==\"TJ GALIARDI\", \"T.J. GALIARDI\", \n",
    "        (np.where(api_events['ep1_name']==\"TOBY ENSTROM\", \"TOBIAS ENSTROM\",  \n",
    "        (np.where(api_events['ep1_name']==\"TREVOR VAN RIEMSDYK\", \"TREVOR VAN RIEMSDYK\", \n",
    "        (np.where(api_events['ep1_name']==\"ZACK FITZGERALD\", \"ZACH FITZGERALD\", \n",
    "\n",
    "        ## NEW CHANGES\n",
    "        (np.where(api_events['ep1_name']==\"TIM GETTINGER\", \"TIMOTHY GETTINGER\", \n",
    "        (np.where(api_events['ep1_name']==\"THOMAS DI PAULI\", \"THOMAS DI PAULI\", \n",
    "        (np.where(api_events['ep1_name']==\"NICHOLAS SHORE\", \"NICK SHORE\",\n",
    "        (np.where(api_events['ep1_name']==\"T.J.  TYNAN\", \"TJ TYNAN\",\n",
    "\n",
    "        ## '20-21 CHANGES (from HTM update function)\n",
    "        (np.where(api_events['ep1_name']==\"ALEXIS LAFRENI?RE\", \"ALEXIS LAFRENIÈRE\",\n",
    "        (np.where(api_events['ep1_name']==\"ALEXIS LAFRENIERE\", \"ALEXIS LAFRENIÈRE\",\n",
    "        (np.where(api_events['ep1_name']==\"TIM STUTZLE\", \"TIM STÜTZLE\",\n",
    "        (np.where(api_events['ep1_name']==\"TIM ST?TZLE\", \"TIM STÜTZLE\",\n",
    "        (np.where(api_events['ep1_name']==\"EGOR SHARANGOVICH\", \"YEGOR SHARANGOVICH\",\n",
    "        (np.where(api_events['ep1_name']==\"CALLAN FOOTE\", \"CAL FOOTE\",\n",
    "        (np.where(api_events['ep1_name']==\"JOSH DUNNE\", \"JOSHUA DUNNE\", api_events['ep1_name']\n",
    "        ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
    "        )))))))))))))))))))))))))))))))))))))))))))))\n",
    "\n",
    "        if drop_description == True:\n",
    "        \n",
    "            return api_events.loc[:, ['game_seconds', 'event', 'coords_x', 'coords_y', 'ep1_name', 'period', 'version']].rename(columns = {'ep1_name':'event_player_1'})\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return api_events.loc[:, ['game_seconds', 'event', 'coords_x', 'coords_y', 'ep1_name', 'period', 'version', 'description']].rename(columns = {'ep1_name':'event_player_1'})\n",
    "        \n",
    "    else:\n",
    "        print(\"This game doesn't exist within the API.\")\n",
    "        raise KeyError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-generator",
   "metadata": {},
   "source": [
    "# SCRAPE HTML EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aboriginal-biodiversity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape_html_events(season, game_id):\n",
    "    #global game\n",
    "    url = 'http://www.nhl.com/scores/htmlreports/' + season + '/PL0' + game_id + '.HTM'\n",
    "    page = requests.get(url)\n",
    "    #if int(season)<20092010:\n",
    "     #   soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    #else:\n",
    "     #   soup = BeautifulSoup(page.content, 'lxml')\n",
    "    soup = BeautifulSoup(page.content.decode('ISO-8859-1'), 'lxml')\n",
    "    tds = soup.find_all(\"td\", {\"class\": re.compile('.*bborder.*')})\n",
    "    #global stripped_html\n",
    "    #global eventdf\n",
    "    stripped_html = hs_strip_html(tds)\n",
    "    length = int(len(stripped_html)/8)\n",
    "    eventdf = pd.DataFrame(np.array(stripped_html).reshape(length, 8)).rename(\n",
    "    columns = {0:'index', 1:'period', 2:'strength', 3:'time', 4:'event', 5:'description', 6:'away_skaters', 7:'home_skaters'})\n",
    "    split = eventdf.time.str.split(':')\n",
    "    game_date = soup.find_all('td', {'align':'center', 'style':'font-size: 10px;font-weight:bold'})[2].get_text()\n",
    "    \n",
    "    potentialnames = soup.find_all('td', {'align':'center', 'style':'font-size: 10px;font-weight:bold'})\n",
    "    \n",
    "    for i in range(0, 999):\n",
    "        away = potentialnames[i].get_text()\n",
    "        if ('Away Game') in away or ('tr./Away') in away:\n",
    "            away = re.split('Match|Game', away)[0]\n",
    "            break\n",
    "        \n",
    "    for i in range(0, 999):\n",
    "        home = potentialnames[i].get_text()\n",
    "        if ('Home Game') in home or ('Dom./Home') in home:\n",
    "            home = re.split('Match|Game', home)[0]\n",
    "            break\n",
    "            \n",
    "    game = eventdf.assign(away_skaters = eventdf.away_skaters.str.replace('\\n', ''),\n",
    "                  home_skaters = eventdf.home_skaters.str.replace('\\n', ''),\n",
    "                  original_time = eventdf.time,\n",
    "                  time = split.str[0] + \":\" + split.str[1].str[:2],\n",
    "                  home_team = home,\n",
    "                  away_team = away)\n",
    "    \n",
    "    game = game.assign(away_team_abbreviated = game.away_skaters[0].split(' ')[0],\n",
    "                       home_team_abbreviated = game.home_skaters[0].split(' ')[0])\n",
    "    \n",
    "    game = game[game.period!='Per']\n",
    "    \n",
    "    game = game.assign(index = game.index.astype(int)).rename(columns = {'index':'event_index'})\n",
    "    \n",
    "    game = game.assign(event_team = game.description.str.split(' ').str[0])\n",
    "    \n",
    "    game = game.assign(event_team = game.event_team.str.split('\\xa0').str[0])\n",
    "    \n",
    "    game = game.assign(event_team = np.where(~game.event_team.isin([game.home_team_abbreviated.iloc[0], game.away_team_abbreviated.iloc[0]]), '', game.event_team))\n",
    "    \n",
    "    game = game.assign(other_team = np.where(game.event_team=='', '',\n",
    "                                            np.where(game.event_team==game.home_team_abbreviated.iloc[0], game.away_team_abbreviated.iloc[0], game.home_team_abbreviated.iloc[0])))\n",
    "    \n",
    "    game['event_player_str'] = game.description.apply(\n",
    "    lambda x: re.findall('(#)(\\d\\d)|(#)(\\d)|(-) (\\d\\d)|(-) (\\d)', x)).astype(str\n",
    "                                                        ).str.replace('#', '').str.replace('-', '').str.replace(\"'\", '').str.replace(',', '').str.replace('(', '').str.replace(')', '').astype(str\n",
    "                                                        ).str.replace('[', '').str.replace(']', '').apply(lambda x: re.sub(' +', ' ', x)).str.strip()\n",
    "\n",
    "    game = game.assign(event_player_1 = \n",
    "            game.event_player_str.str.split(' ').str[0],\n",
    "            event_player_2 = \n",
    "            game.event_player_str.str.split(' ').str[1],\n",
    "            event_player_3 = \n",
    "            game.event_player_str.str.split(' ').str[2])\n",
    "    #return game\n",
    "\n",
    "    if len(game[game.description.str.contains('Drawn by')])>0:\n",
    "    \n",
    "        game = game.assign(event_player_2 = np.where(game.description.str.contains('Drawn By'), \n",
    "                                          game.description.str.split('Drawn By').str[1].str.split('#').str[1].str.split(' ').str[0].str.strip(), \n",
    "                                          game.event_player_2),\n",
    "                          event_player_3 = np.where(game.description.str.contains('Served By'),\n",
    "                                                   np.nan,\n",
    "                                                   game.event_player_3))\n",
    "\n",
    "    game = game.assign(event_player_1 = np.where((~pd.isna(game.event_player_1)) & (game.event_player_1!=''),\n",
    "                              np.where(game.event=='FAC', game.away_team_abbreviated,\n",
    "                                       game.event_team) + (game.event_player_1.astype(str)), \n",
    "                              game.event_player_1),\n",
    "                  event_player_2 = np.where((~pd.isna(game.event_player_2)) & (game.event_player_2!=''),\n",
    "                              np.where(game.event=='FAC', game.home_team_abbreviated,\n",
    "                                       np.where(game.event.isin(['BLOCK', 'HIT', 'PENL']), game.other_team, game.event_team)) + (game.event_player_2.astype(str)), \n",
    "                              game.event_player_2),\n",
    "                  event_player_3 = np.where((~pd.isna(game.event_player_3)) & (game.event_player_3!=''),\n",
    "                              game.event_team + (game.event_player_3.astype(str)), \n",
    "                              game.event_player_3))\n",
    "    \n",
    "    game = game.assign(\n",
    "        event_player_1 = np.where((game.event=='FAC') & (game.event_team==game.home_team_abbreviated),\n",
    "                                 game.event_player_2, game.event_player_1),\n",
    "        event_player_2 = np.where((game.event=='FAC') & (game.event_team==game.home_team_abbreviated),\n",
    "                                 game.event_player_1, game.event_player_2))\n",
    "    \n",
    "    #return game\n",
    "    \n",
    "    roster = scrape_html_roster(season, game_id).rename(columns = {'Nom/Name':'Name'})\n",
    "    roster = roster[roster.status=='player']\n",
    "    roster = roster.assign(team_abbreviated = np.where(roster.team=='home', \n",
    "                                                       game.home_team_abbreviated.iloc[0],\n",
    "                                                      game.away_team_abbreviated.iloc[0]))\n",
    "\n",
    "    roster = roster.assign(teamnum = roster.team_abbreviated + roster['#'],\n",
    "                          Name = roster.Name.str.split('(').str[0].str.strip())\n",
    "    \n",
    "    event_player_1s = roster.loc[:, ['teamnum', 'Name']].rename(columns = {'teamnum':'event_player_1', 'Name':'ep1_name'})\n",
    "    event_player_2s = roster.loc[:, ['teamnum', 'Name']].rename(columns = {'teamnum':'event_player_2', 'Name':'ep2_name'})\n",
    "    event_player_3s = roster.loc[:, ['teamnum', 'Name']].rename(columns = {'teamnum':'event_player_3', 'Name':'ep3_name'})\n",
    "    \n",
    "    game = game.merge(\n",
    "    event_player_1s, on = 'event_player_1', how = 'left').merge(\n",
    "    event_player_2s, on = 'event_player_2', how = 'left').merge(\n",
    "    event_player_3s, on = 'event_player_3', how = 'left').assign(\n",
    "    date = game_date)\n",
    "    #return game\n",
    "    \n",
    "    game['period'] = game.period.astype(int)\n",
    "\n",
    "    game['period_seconds'] = game.time.str.split(':').str[0].str.replace('-', '').astype(int) * 60 + game.time.str.split(':').str[1].str.replace('-', '').astype(int)\n",
    "\n",
    "    game['game_seconds'] = (np.where(game.period<5, \n",
    "                                       (((game.period - 1) * 1200) + game.period_seconds),\n",
    "                              3900))\n",
    "    \n",
    "    game = game.assign(priority = np.where(game.event.isin(['TAKE', 'GIVE', 'MISS', 'HIT', 'SHOT', 'BLOCK']), 1, \n",
    "                                            np.where(game.event==\"GOAL\", 2,\n",
    "                                                np.where(game.event==\"STOP\", 3,\n",
    "                                                    np.where(game.event==\"DELPEN\", 4,\n",
    "                                                        np.where(game.event==\"PENL\", 5,\n",
    "                                                            np.where(game.event==\"CHANGE\", 6,\n",
    "                                                                np.where(game.event==\"PEND\", 7,\n",
    "                                                                    np.where(game.event==\"GEND\", 8,\n",
    "                                                                        np.where(game.event==\"FAC\", 9, 0)))))))))).sort_values(by = ['game_seconds', 'period', 'event_player_1', 'event'])\n",
    "    game = game.assign(version = \n",
    "                       (np.where(\n",
    "                       (game.event==game.event.shift()) & \n",
    "                       (game.event_player_1==game.event_player_1.shift()) &\n",
    "                       (game.event_player_1!='') &\n",
    "                       (game.game_seconds==game.game_seconds.shift()),\n",
    "                        1, 0)))\n",
    "    \n",
    "    game = game.assign(version = \n",
    "                           (np.where(\n",
    "                           (game.event==game.event.shift(2)) & \n",
    "                           (game.event_player_1==game.event_player_1.shift(2)) &\n",
    "                           (game.game_seconds==game.game_seconds.shift(2)) & \n",
    "                           (game.event_player_1!='') &\n",
    "                           (~game.description.str.contains('Penalty Shot')),\n",
    "                            2, game.version)))\n",
    "    \n",
    "    game = game.assign(version = \n",
    "                           (np.where(\n",
    "                           (game.event==game.event.shift(3)) & \n",
    "                           (game.event_player_1==game.event_player_1.shift(3)) &\n",
    "                           (game.game_seconds==game.game_seconds.shift(3)) & \n",
    "                           (game.event_player_1!=''),\n",
    "                            3, game.version)))\n",
    "    \n",
    "    game = game.assign(date = pd.to_datetime(game.date[~pd.isna(game.date)].iloc[0])\n",
    "                  ).rename(columns = {'date':'game_date'}).sort_values(by = ['event_index'])\n",
    "    \n",
    "    game = game.assign(event_player_1 = game.ep1_name, event_player_2 = game.ep2_name, event_player_3 = game.ep3_name).drop(columns = ['ep1_name', 'ep2_name', 'ep3_name'])\n",
    "    \n",
    "    game = game.assign(home_team = np.where(game.home_team=='CANADIENS MONTREAL', 'MONTREAL CANADIENS', game.home_team),\n",
    "                      away_team = np.where(game.away_team=='CANADIENS MONTREAL', 'MONTREAL CANADIENS', game.away_team))\n",
    "    \n",
    "    game = game[game.game_seconds<4000]\n",
    "    \n",
    "    game['game_date'] = np.where((season=='20072008') & (game_id == '20003'), game.game_date + pd.Timedelta(days=1), game.game_date)\n",
    "    \n",
    "    game = game.assign(event_player_1 = np.where((game.description.str.upper().str.contains('TEAM')) | (game.description.str.lower().str.contains('bench')),\n",
    "                                     'BENCH',\n",
    "                                     game.event_player_1))\n",
    "    \n",
    "    game = game.assign(home_skater_count_temp = (game.home_skaters.apply(lambda x: len(re.findall('[A-Z]', x)))),\n",
    "          away_skater_count_temp = (game.away_skaters.apply(lambda x: len(re.findall('[A-Z]', x))))\n",
    "         )\n",
    "    \n",
    "    game = game.assign(event_team = np.where((game.event=='PENL') & (game.event_team=='') & (game.description.str.lower().str.contains('bench')) & (game.home_skater_count_temp>game.home_skater_count_temp.shift(-1)),\n",
    "                                game.home_team_abbreviated, game.event_team))\n",
    "\n",
    "    game = game.assign(event_team = np.where((game.event=='PENL') & (game.event_team=='') & (game.description.str.lower().str.contains('bench')) & (game.away_skater_count_temp>game.away_skater_count_temp.shift(-1)),\n",
    "                                game.away_team_abbreviated, game.event_team))\n",
    "    \n",
    "    return game.drop(columns = ['period_seconds', 'time', 'priority', 'home_skater_count_temp', 'away_skater_count_temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "outdoor-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = scrape_html_events('20202021', '20215')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-rating",
   "metadata": {},
   "source": [
    "# Scrape ESPN XML Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "stuffed-symbol",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape_espn_events(espn_game_id, drop_description = True):\n",
    "    \n",
    "    ### NEED TO FIX PENALTY SHOTS ##\n",
    "    \n",
    "    # Hawks ID: 270114004\n",
    "    # Sharks ID: 401272106\n",
    "    # Habs game: 401044320\n",
    "    # Flames game (first goal unasssisted): 401320053\n",
    "\n",
    "    url = 'https://www.espn.com/nhl/gamecast/data/masterFeed?lang=en&isAll=true&rand=0&gameId=' + str(espn_game_id)\n",
    "    page = requests.get(url, timeout = 500)\n",
    "    try:\n",
    "        dictionary = xmltodict.parse(page.content.decode('ISO-8859-1'))\n",
    "    except ExpatError as e:\n",
    "        problem = int(str(e).split('column')[1].strip())\n",
    "        problem_value = page.content.decode('ISO-8859-1')[problem]\n",
    "        dictionary = xmltodict.parse(page.content.decode('ISO-8859-1').replace(problem_value, ''))\n",
    "    if (dictionary['NHLGamecast']['Plays']) is None:\n",
    "        raise IndexError('This game has no events.')\n",
    "    playdict = (dictionary['NHLGamecast']['Plays']['Play'])\n",
    "    global play_list\n",
    "    play_list = []\n",
    "    play_id_list = []\n",
    "\n",
    "    for i in range(0, len(playdict)):\n",
    "        play_list.append(playdict[i]['#text'])\n",
    "        play_id_list.append(playdict[i]['@id'])\n",
    "\n",
    "    x_coordinates = []\n",
    "    y_coordinates = []\n",
    "    game_mins = []\n",
    "    game_secs = []\n",
    "    game_pd = []\n",
    "    event_desc = []\n",
    "\n",
    "    for i in range (0, len(play_list)):\n",
    "        split = play_list[i].split('~')\n",
    "        x_coordinates.append(split[0])\n",
    "        y_coordinates.append(split[1])\n",
    "        game_mins.append(play_list[i].split(':')[0].split('~')[-1])\n",
    "        game_secs.append(play_list[i].split(':')[1].split('~')[0].split('-')[0])\n",
    "        event_desc.append(\" \".join(re.findall(\"[a-z-'.A-Z]+|\\dst|\\drd|\\d2nd|\\d  minutes|\\d minutes\", play_list[i])))\n",
    "        if (len(re.split(r'(:\\d+)~', play_list[i])))>1:\n",
    "            game_pd.append((re.split(r'(:\\d+)~', play_list[i])[2][0]))\n",
    "        else:\n",
    "            game_pd.append(re.split('-\\d~|-\\d:\\d-\\d~', play_list[i])[1][0])\n",
    "            \n",
    "            \n",
    "    #event_desc.append(\" \".join(re.findall(\"[a-zA-Z]+\", play_list[i])))\n",
    "    # Below is the code to get information that includes period number and penalty minutes. It is timely and unncessary.\n",
    "    \n",
    "    \n",
    "    espn_events = pd.DataFrame()\n",
    "    \n",
    "    #for i in range(0, len(game_secs)):\n",
    "     #   print((int(game_secs[i])))\n",
    "\n",
    "    espn_events = espn_events.assign(\n",
    "    coords_x = x_coordinates,\n",
    "    coords_y = y_coordinates,\n",
    "    period = game_pd,\n",
    "    minutes = game_mins,\n",
    "    seconds = game_secs,\n",
    "    description = event_desc)\n",
    "\n",
    "    espn_events = espn_events.assign(\n",
    "    coords_x = espn_events.coords_x.astype(int),\n",
    "    coords_y = espn_events.coords_y.astype(int),\n",
    "    period = espn_events.period.astype(int),\n",
    "    minutes = espn_events.minutes.astype(int),\n",
    "    seconds = espn_events.seconds.astype(int),\n",
    "    description = espn_events.description.str.strip('-|- -').str.strip()).sort_values(by = ['period', 'minutes', 'seconds'])\n",
    "    espn_events['minutes'] = np.where(espn_events.minutes<0, 0, espn_events.minutes)\n",
    "    \n",
    "    espn_events['duplicated_description'] = espn_events['description']\n",
    "\n",
    "    espn_events['duplicated_description'] = espn_events['description']\n",
    "\n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: x.split('Giveaway by')[1].split(' in')[0].strip() if 'Giveaway by' in x else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "\n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: x.split('Takeaway by')[1].split(' in')[0].strip() if 'Takeaway by' in x else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "\n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: x.split('credited with hit')[0].split('credited')[0].strip() if 'credited with hit' in x else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "\n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: x.split('won faceoff')[0].strip() if 'faceoff' in x else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "\n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: re.split('Wristshot|Tip-In|Snapshot|Backhand|Slapshot|Deflection|Wraparound',\n",
    "                           re.split('scored by|Scored by', x)[1].split('assisted by')[0].split('unassisted')[0].split('Power')[0].split('Empty')[0].split('Shorthanded')[0])[0].strip() if (\n",
    "            'Goal Scored' in x or 'Goal scored' in x or 'Shootout GOAL' in x) and x!='Goal scored' else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "\n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: re.split('Shot blocked by', x)[1].strip() if 'Shot blocked by' in x else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "    \n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: re.split('shot blocked', x)[0].strip() if 'blocked' in x else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "\n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: re.split('Shot blocked', x)[1].strip() if 'block' in x else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "    \n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: re.split('missed by', x)[1].split('Wide')[0].split('Over')[0].split('Goalpost')[0].split('Hit')[0].strip() if 'missed by' in x else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "\n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: re.split('Wristshot|Tip-In|Snapshot|Backhand|Slapshot|Deflection|Saved|Wraparound', re.split('Shot on goal by', x)[1].split('saved')[0].split('ft')[0].split('shootout')[0] if 'Shot on goal' in x and x!='Shot on goal' else x)[0].strip())\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "\n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: re.split('0|2|4|5|10', re.split('Penalty to', x)[1].split('minutes')[0])[0].strip() if 'Penalty to' in x else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "\n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: re.split('saved|MISSES|SAVED', x.split('Shootout attempt by')[1])[0].split('saved')[0].strip() if 'Shootout attempt by' in x else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "\n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: x.split(' on ')[0].strip() if ' on ' in x else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "    \n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: 'BENCH' if 'Bench' in x and 'Penalty' in x else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "    \n",
    "    espn_events['event_player_1'] = espn_events['duplicated_description'].apply(\n",
    "        lambda x: x.split('shootout')[0].strip() if 'shootout attempt against' in x else x)\n",
    "    espn_events['duplicated_description'] = np.where(espn_events['event_player_1']!=espn_events['duplicated_description'], espn_events['event_player_1'], espn_events['duplicated_description'])\n",
    "    \n",
    "    espn_events = espn_events.assign(event_type = np.where((espn_events.description.str.contains(\"Penalty\")) | ((espn_events.description.str.contains(\"Bench penalty\"))),\n",
    "    \"PENL\",\n",
    "    (np.where(((espn_events.description.str.contains(\"Shot on goal\")) | \n",
    "    (espn_events.description.str.contains('Shootout attempt by *.* saved')) |\n",
    "    (espn_events.description.str.contains('Shootout attempt by *.* SAVED')) |\n",
    "    (espn_events.description.str.contains(\"shootout attempt *.* results in a SAVE\"))),\n",
    "    \"SHOT\",\n",
    "    (np.where(((espn_events.description.str.contains(\"Shot missed\")) |\n",
    "    (espn_events.description.str.contains('Shootout attempt by *.* MISSES')) |\n",
    "    (espn_events.description.str.contains(\"shootout attempt *.* results in a MISS\"))),\n",
    "    \"MISS\",\n",
    "    (np.where(espn_events.description.str.contains(\"faceoff\"),\n",
    "    \"FAC\",\n",
    "    (np.where(espn_events.description.str.contains(\"blocked\"),\n",
    "    \"BLOCK\",\n",
    "    (np.where(espn_events.description.str.contains(\"credited with hit\"),\n",
    "    \"HIT\",\n",
    "    (np.where((espn_events.description.str.contains(\"Giveaway by\")) | (espn_events.description.str.contains(\"Giveaway in\")),\n",
    "    \"GIVE\",\n",
    "    (np.where((espn_events.description.str.contains(\"Takeaway by\")) | (espn_events.description.str.contains(\"Takeaway in\")),\n",
    "    \"TAKE\",\n",
    "    (np.where(espn_events.description.str.contains(\"Goal Scored|Goal scored|GOAL scored|shootout attempt *.* results in a GOAL\"),\n",
    "    \"GOAL\",\n",
    "    (np.where(espn_events.description.str.contains(\"Start of\"),\n",
    "    \"PSTR\",\n",
    "    (np.where((espn_events.description.str.contains(\"End of\")) & \n",
    "          (espn_events.description.str!=\"End of Game\"),\n",
    "    \"PEND\",\n",
    "    (np.where(espn_events.description.str.contains(\"Stoppage\"),\n",
    "     \"STOP\",  \n",
    "        (np.where(espn_events.description=='End of Game',\n",
    "         \"GEND\",  \n",
    "    '\\xa0'))))))))))))))))))))))))))#.loc[:, ['game_seconds', 'description','event_type',  'coords_x', 'coords_y', 'event_player_1']]\n",
    "    espn_events = espn_events.assign(\n",
    "        event_player_1 = np.where(espn_events.event_player_1==espn_events.description, '\\xa0', espn_events.event_player_1))\n",
    "    \n",
    "    espn_events = espn_events.assign(priority = np.where(espn_events.event_type.isin(['TAKE', 'GIVE', 'MISS', 'HIT', 'SHOT', 'BLOCK']), 1, \n",
    "                                            np.where(espn_events.event_type==\"GOAL\", 2,\n",
    "                                                np.where(espn_events.event_type==\"STOP\", 3,\n",
    "                                                    np.where(espn_events.event_type==\"DELPEN\", 4,\n",
    "                                                        np.where(espn_events.event_type==\"PENL\", 5,\n",
    "                                                            np.where(espn_events.event_type==\"CHANGE\", 6,\n",
    "                                                                np.where(espn_events.event_type==\"PEND\", 7,\n",
    "                                                                    np.where(espn_events.event_type==\"GEND\", 8,\n",
    "                                                                        np.where(espn_events.event_type==\"FAC\", 9, 0))))))))),\n",
    "                                    event_player_1 = espn_events.event_player_1.str.upper(),\n",
    "                                    game_seconds = np.where(espn_events.period<5, \n",
    "                                    ((espn_events.period - 1) * 1200) + (espn_events.minutes * 60) + espn_events.seconds, 3900))\n",
    "    espn_events['game_seconds'] = espn_events.game_seconds.astype(int)\n",
    "    espn_events = espn_events.sort_values(by = ['period', 'game_seconds', 'event_player_1', 'priority']).rename(\n",
    "    columns = {'event_type':'event'}).loc[:, ['coords_x', 'coords_y', 'event_player_1', 'event', 'game_seconds', 'description', 'period']]\n",
    "    \n",
    "    espn_events['event_player_1'] = np.where(espn_events['event_player_1'].str.contains('ALEXANDRE '), \n",
    "                                espn_events['event_player_1'].str.replace('ALEXANDRE ', 'ALEX '),\n",
    "                                espn_events['event_player_1'])\n",
    "    \n",
    "    espn_events['event_player_1'] = np.where(espn_events['event_player_1'].str.contains('ALEXANDER '), \n",
    "                                espn_events['event_player_1'].str.replace('ALEXANDER ', 'ALEX '),\n",
    "                                espn_events['event_player_1'])\n",
    "    \n",
    "    espn_events['event_player_1'] = np.where(espn_events['event_player_1'].str.contains('CHRISTOPHER '), \n",
    "                                espn_events['event_player_1'].str.replace('CHRISTOPHER ', 'CHRIS '),\n",
    "                                espn_events['event_player_1'])\n",
    "    \n",
    "    espn_events = espn_events.assign(event_player_1 = \n",
    "    np.where(espn_events.event_player_1=='PATRICK MAROON', 'PAT MAROON',\n",
    "    (np.where(espn_events.event_player_1=='J T COMPHER', 'J.T. COMPHER', \n",
    "    (np.where(espn_events.event_player_1=='J T MILLER', 'J.T. MILLER', \n",
    "    (np.where(espn_events.event_player_1=='T J OSHIE', 'T.J. OSHIE', \n",
    "    (np.where((espn_events.event_player_1=='ALEXIS LAFRENIERE') | (espn_events.event_player_1=='ALEXIS LAFRENI RE'), 'ALEXIS LAFRENIÈRE', \n",
    "    (np.where((espn_events.event_player_1=='TIM STUTZLE') | (espn_events.event_player_1=='TIM ST TZLE'), 'TIM STÜTZLE',\n",
    "    (np.where(espn_events.event_player_1=='T.J. BRODIE', 'TJ BRODIE',\n",
    "    (np.where(espn_events.event_player_1=='MATTHEW IRWIN', 'MATT IRWIN',\n",
    "    (np.where(espn_events.event_player_1=='STEVE KAMPFER', 'STEVEN KAMPFER',\n",
    "    (np.where(espn_events.event_player_1=='STEVE KAMPFER', 'STEVEN KAMPFER',\n",
    "    (np.where(espn_events.event_player_1=='JEFFREY TRUCHON-VIEL', 'JEFFREY VIEL',\n",
    "    (np.where(espn_events.event_player_1=='ZACHARY JONES', 'ZAC JONES',\n",
    "    (np.where(espn_events.event_player_1=='MITCH MARNER', 'MITCHELL MARNER',\n",
    "    (np.where(espn_events.event_player_1=='MATHEW DUMBA', 'MATT DUMBA',\n",
    "    (np.where(espn_events.event_player_1=='JOSHUA MORRISSEY', 'JOSH MORRISSEY',\n",
    "    (np.where(espn_events.event_player_1=='P K SUBBAN', 'P.K. SUBBAN',\n",
    "    (np.where(espn_events.event_player_1=='EGOR SHARANGOVICH', 'YEGOR SHARANGOVICH',\n",
    "    (np.where(espn_events.event_player_1=='MAXIME COMTOIS', 'MAX COMTOIS',\n",
    "    (np.where(espn_events.event_player_1=='NICHOLAS CAAMANO', 'NICK CAAMANO',\n",
    "    (np.where(espn_events.event_player_1=='DANIEL CARCILLO', 'DAN CARCILLO',\n",
    "    (np.where(espn_events.event_player_1=='ALEXANDER OVECHKIN', 'ALEX OVECHKIN',\n",
    "    (np.where(espn_events.event_player_1=='MICHAEL CAMMALLERI', 'MIKE CAMMALLERI',\n",
    "    (np.where(espn_events.event_player_1=='DAVE STECKEL', 'DAVID STECKEL',\n",
    "    (np.where(espn_events.event_player_1=='JIM DOWD', 'JAMES DOWD', \n",
    "    (np.where(espn_events.event_player_1=='MAXIME TALBOT', 'MAX TALBOT',\n",
    "    (np.where(espn_events.event_player_1=='MIKE ZIGOMANIS', 'MICHAEL ZIGOMANIS',\n",
    "    (np.where(espn_events.event_player_1=='VINNY PROSPAL', 'VACLAV PROSPAL',\n",
    "    (np.where(espn_events.event_player_1=='MIKE YORK', 'MICHAEL YORK',\n",
    "    (np.where(espn_events.event_player_1=='JACOB DOWELL', 'JAKE DOWELL',\n",
    "    (np.where(espn_events.event_player_1=='MICHAEL RUPP', 'MIKE RUPP',\n",
    "    (np.where(espn_events.event_player_1=='ALEXEI KOVALEV', 'ALEX KOVALEV',\n",
    "    (np.where(espn_events.event_player_1=='SLAVA KOZLOV', 'VYACHESLAV KOZLOV',\n",
    "    (np.where(espn_events.event_player_1=='JEFF HAMILTON', 'JEFFREY HAMILTON',\n",
    "    (np.where(espn_events.event_player_1=='JOHNNY POHL', 'JOHN POHL',\n",
    "    (np.where(espn_events.event_player_1=='DANIEL GIRARDI', 'DAN GIRARDI',\n",
    "    (np.where(espn_events.event_player_1=='NIKOLAI ZHERDEV', 'NIKOLAY ZHERDEV',\n",
    "    (np.where(espn_events.event_player_1=='J.P. DUMONT', 'J-P DUMONT',\n",
    "    (np.where(espn_events.event_player_1=='DWAYNE KING', 'DJ KING',\n",
    "    (np.where(espn_events.event_player_1=='JOHN ODUYA', 'JOHNNY ODUYA',\n",
    "    (np.where(espn_events.event_player_1=='ROBERT SCUDERI', 'ROB SCUDERI',\n",
    "    (np.where(espn_events.event_player_1=='DOUG MURRAY', 'DOUGLAS MURRAY',\n",
    "    (np.where(espn_events.event_player_1=='VACLAV PROSPAL', 'VINNY PROSPAL',\n",
    "    (np.where(espn_events.event_player_1=='RICH PEVERLY', 'RICH PEVERLEY',\n",
    "    espn_events.event_player_1.str.strip()\n",
    "             ))))))))))))))))))))))))))))))))))))))))))))\n",
    "             ))))))))))))))))))))))))))))))))))))))))))\n",
    "    \n",
    "    espn_events = espn_events.assign(version = \n",
    "                       (np.where(\n",
    "                       (espn_events.event==espn_events.event.shift()) & \n",
    "                       (espn_events.event_player_1==espn_events.event_player_1.shift()) &\n",
    "                       (espn_events.event_player_1!='') &\n",
    "                       (espn_events.game_seconds==espn_events.game_seconds.shift()),\n",
    "                        1, 0)))\n",
    "    \n",
    "    espn_events = espn_events.assign(version = \n",
    "                           (np.where(\n",
    "                           (espn_events.event==espn_events.event.shift(2)) & \n",
    "                           (espn_events.event_player_1==espn_events.event_player_1.shift(2)) &\n",
    "                           (espn_events.game_seconds==espn_events.game_seconds.shift(2)) & \n",
    "                           (espn_events.event_player_1!='') &\n",
    "                           (~espn_events.description.str.contains('Penalty Shot')),\n",
    "                            2, espn_events.version)))\n",
    "    \n",
    "    espn_events = espn_events.assign(version = \n",
    "                           (np.where(\n",
    "                           (espn_events.event==espn_events.event.shift(3)) & \n",
    "                           (espn_events.event_player_1==espn_events.event_player_1.shift(3)) &\n",
    "                           (espn_events.game_seconds==espn_events.game_seconds.shift(3)) & \n",
    "                           (espn_events.event_player_1!=''),\n",
    "                            3, espn_events.version)))\n",
    "    \n",
    "    espn_events['espn_id'] = int(espn_game_id)\n",
    "    \n",
    "    espn_events['event_player_1'] = espn_events['event_player_1'].str.strip()\n",
    "    \n",
    "    #espn_events = espn_events.assign(event_player_1 = np.where(\n",
    "    #espn_events.event_player_1=='ALEX BURROWS', 'ALEXANDRE BURROWS', espn_events.event_player_1))\n",
    "    \n",
    "    global look\n",
    "    look = espn_events\n",
    "    \n",
    "    espn_events['coords_x'] = espn_events['coords_x'] + 1\n",
    "    espn_events['coords_y'] = espn_events['coords_y'] - 1\n",
    "    \n",
    "    if drop_description == True:\n",
    "        return espn_events.drop(columns = 'description')\n",
    "    else:\n",
    "        return espn_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-prime",
   "metadata": {},
   "source": [
    "# GET ESPN IDS FROM GAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "major-violence",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape_espn_ids_single_game(game_date, home_team, away_team):\n",
    "    gamedays = pd.DataFrame()\n",
    "    \n",
    "    if home_team == 'ATLANTA THRASHERS':\n",
    "        home_team = 'WINNIPEG JETS'\n",
    "    if away_team == 'ATLANTA THRASHERS':\n",
    "        away_team = 'WINNIPEG JETS'\n",
    "        \n",
    "    if home_team == 'PHOENIX COYOTES':\n",
    "        home_team = 'ARIZONA COYOTES'\n",
    "    if away_team == 'PHOENIX COYOTES':\n",
    "        away_team = 'ARIZONA COYOTES'\n",
    "    \n",
    "    this_date = (game_date)\n",
    "    url = 'http://www.espn.com/nhl/scoreboard?date=' + this_date.replace(\"-\", \"\")\n",
    "    page = requests.get(url, timeout = 500)\n",
    "    soup = BeautifulSoup(page.content, parser = 'lxml')\n",
    "    soup_found = soup.find_all('a', {'class':['AnchorLink truncate', 'AnchorLink Button Button--sm Button--anchorLink Button--alt mb4 w-100'], 'href':[re.compile(\"/nhl/team/_/name/\"), re.compile(\"game/_\")]})\n",
    "    at = []\n",
    "    ht = []\n",
    "    gids = []\n",
    "    fax = pd.DataFrame()\n",
    "    #print(str(i))\n",
    "    for i in range (0, (int(len(soup_found)/3))):\n",
    "        away = soup_found[0 + (i * 3)]['href'].rsplit('/')[-1].replace('-', ' ').upper()\n",
    "        home = soup_found[1 + (i * 3)]['href'].rsplit('/')[-1].replace('-', ' ').upper()\n",
    "        espnid = soup_found[2 + (i * 3)]['href'].split('gameId/', 1)[1]\n",
    "        at.append(away)\n",
    "        ht.append(home)\n",
    "        gids.append(espnid)\n",
    "\n",
    "    fax = fax.assign(\n",
    "    away_team = at,\n",
    "    home_team = ht,\n",
    "    espn_id = gids,\n",
    "    game_date = pd.to_datetime(this_date))\n",
    "\n",
    "    gamedays = gamedays.append(fax)\n",
    "\n",
    "    gamedays = gamedays.assign(\n",
    "        home_team = np.where(gamedays.home_team=='ST LOUIS BLUES', 'ST. LOUIS BLUES', gamedays.home_team),\n",
    "        away_team = np.where(gamedays.away_team=='ST LOUIS BLUES', 'ST. LOUIS BLUES', gamedays.away_team),\n",
    "        espn_id = gamedays.espn_id.astype(int))\n",
    "    \n",
    "    #gamedays = gamedays.assign(\n",
    "     #   home_team = np.where(gamedays.home_team=='WINNIPEG JETS', 'ATLANTA THRASHERS', gamedays.home_team),\n",
    "      #  away_team = np.where(gamedays.away_team=='WINNIPEG JETS', 'ATLANTA THRASHERS', gamedays.away_team),\n",
    "       # espn_id = gamedays.espn_id.astype(int))\n",
    "    \n",
    "    gamedays = gamedays[(gamedays.game_date==this_date) & (gamedays.home_team==home_team) & (gamedays.away_team==away_team)]\n",
    "        \n",
    "    return gamedays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-thomson",
   "metadata": {},
   "source": [
    "# MERGE AND PREPARE EVENTS AND SHIFTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "stone-lesson",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_and_prepare(events, shifts):\n",
    "    \n",
    "    season = str(int(str(events.game_id.iloc[0])[:4])) + str(int(str(events.game_id.iloc[0])[:4]) + 1)\n",
    "    small_id = str(events.game_id.iloc[0])[5:]\n",
    "    game_id = int(events.game_id.iloc[0])\n",
    "    \n",
    "    merged = pd.concat([events, shifts])\n",
    "    \n",
    "    merged = merged.assign(home_team = merged[~(pd.isna(merged.home_team))].home_team.iloc[0],\n",
    "                          away_team = merged[~(pd.isna(merged.away_team))].away_team.iloc[0],\n",
    "                          home_team_abbreviated = merged[~(pd.isna(merged.home_team_abbreviated))].home_team_abbreviated.iloc[0],\n",
    "                          away_team_abbreviated = merged[~(pd.isna(merged.away_team_abbreviated))].away_team_abbreviated.iloc[0])\n",
    "\n",
    "    merged = merged.assign(event_team = np.where(merged.team==merged.home_team, merged.home_team_abbreviated, \n",
    "                                        np.where(merged.team==merged.away_team, merged.away_team_abbreviated, \n",
    "                                                 merged.event_team)))\n",
    "\n",
    "    merged = merged.assign(event = np.where((pd.isna(merged.event)) & \n",
    "                                     ((~pd.isna(merged.number_off)) | (~pd.isna(merged.number_on))), \"CHANGE\", merged.event))\n",
    "\n",
    "    home_space = ' ' + merged['home_team_abbreviated'].iloc[0]\n",
    "    away_space = ' ' + merged['away_team_abbreviated'].iloc[0]\n",
    "\n",
    "    merged['away_skaters'] = np.where(pd.isna(merged.away_skaters), '\\xa0', merged.away_skaters)\n",
    "\n",
    "    merged['tmp'] = merged.away_skaters.str.replace(\"[^0-9]\", \" \")\n",
    "\n",
    "    merged['tmp2'] = (merged.tmp.str.strip().str.split(\"  \")).apply(lambda x: natsorted(x)).apply(lambda x: ' '.join(x))\n",
    "\n",
    "    merged['tmp2'] = (merged.away_team_abbreviated.iloc[0] + merged.tmp2).str.replace(\" \", away_space).str.replace(\" \", \", \")\n",
    "\n",
    "    merged['tmp2'] = np.where(merged.tmp2.str.strip()==merged.away_team_abbreviated.iloc[0], '\\xa0', merged.tmp2)\n",
    "\n",
    "    merged['away_on_ice'] = merged['tmp2']\n",
    "\n",
    "    merged['home_skaters'] = np.where(pd.isna(merged.home_skaters), '\\xa0', merged.home_skaters)\n",
    "\n",
    "    merged['tmp'] = merged.home_skaters.str.replace(\"[^0-9]\", \" \")\n",
    "\n",
    "    merged['tmp2'] = (merged.tmp.str.strip().str.split(\"  \")).apply(lambda x: natsorted(x)).apply(lambda x: ' '.join(x))\n",
    "\n",
    "    merged['tmp2'] = (merged.home_team_abbreviated.iloc[0] + merged.tmp2).str.replace(\" \", home_space).str.replace(\" \", \", \")\n",
    "\n",
    "    merged['tmp2'] = np.where(merged.tmp2.str.strip()==merged.home_team_abbreviated.iloc[0], '\\xa0', merged.tmp2)\n",
    "\n",
    "    merged['home_on_ice'] = merged['tmp2']\n",
    "\n",
    "    merged = merged.sort_values(by = ['game_seconds', 'period'])\n",
    "\n",
    "    merged = merged.assign(jumping_on = (np.where(merged.home_team == merged.team, (merged.home_team_abbreviated.iloc[0] + merged.on_numbers).str.replace(\", \", home_space).str.replace(\" \", \", \"), \n",
    "                                   np.where(merged.away_team == merged.team, (merged.away_team_abbreviated.iloc[0] + merged.on_numbers).str.replace(\", \", away_space).str.replace(\" \", \", \"),\n",
    "                                            np.nan))),\n",
    "                          jumping_off = (np.where(merged.home_team == merged.team, (merged.home_team_abbreviated.iloc[0] + merged.off_numbers).str.replace(\", \", home_space).str.replace(\" \", \", \"), \n",
    "                                   np.where(merged.away_team == merged.team, (merged.away_team_abbreviated.iloc[0] + merged.off_numbers).str.replace(\", \", away_space).str.replace(\" \", \", \"),\n",
    "                                            np.nan))),\n",
    "                          prio = np.where(merged.event==\"CHANGE\", 0,\n",
    "                                          np.where(merged.event.isin(['PGSTR', 'PGEND', 'PSTR', 'PEND', 'ANTHEM']), -1, 1))).sort_values(\n",
    "        by = ['game_seconds', 'period', 'event_index'])\n",
    "\n",
    "    merged = merged.assign(change_before_event = np.where(\n",
    "        (\n",
    "            (merged.away_on_ice!='\\xa0') & (merged.event.shift()=='CHANGE') & (merged.away_on_ice!=merged.away_on_ice.shift()) | \n",
    "            (merged.home_on_ice!='\\xa0') & (merged.event.shift()=='CHANGE') & (merged.home_on_ice!=merged.home_on_ice.shift())\n",
    "        ), 1, 0\n",
    "    ))\n",
    "\n",
    "    merged = merged.assign(change_prio = \n",
    "                          np.where((merged.team==merged.home_team) & (merged.event=='CHANGE') , 1,\n",
    "                                  np.where((merged.team==merged.away_team) & (merged.event=='CHANGE'), -1, 0)))\n",
    "\n",
    "    merged = merged.assign(priority = np.where(merged.event.isin(['TAKE', 'GIVE', 'MISS', 'HIT', 'SHOT', 'BLOCK']), 1, \n",
    "                                                np.where(merged.event==\"GOAL\", 2,\n",
    "                                                    np.where(merged.event==\"STOP\", 3,\n",
    "                                                        np.where(merged.event==\"DELPEN\", 4,\n",
    "                                                            np.where(merged.event==\"PENL\", 5,\n",
    "                                                                np.where(merged.event==\"CHANGE\", 6,\n",
    "                                                                    np.where(merged.event==\"PEND\", 7,\n",
    "                                                                        np.where(merged.event==\"GEND\", 8,\n",
    "                                                                            np.where(merged.event==\"FAC\", 9, 0)))))))))).sort_values(by = ['game_seconds', 'period', 'priority', 'event_index', 'change_prio'])\n",
    "\n",
    "    merged = merged.reset_index(drop = True).reset_index().rename(columns = {'index':'event_index', 'event_index':'original_index'})\n",
    "\n",
    "    global roster\n",
    "\n",
    "    roster = scrape_html_roster(season, small_id).rename(columns = {'Nom/Name':'Name'})\n",
    "\n",
    "    roster = roster.assign(team_abbreviated = np.where(roster.team=='home', \n",
    "                                                       merged.home_team_abbreviated.iloc[0],\n",
    "                                                      merged.away_team_abbreviated.iloc[0]))\n",
    "\n",
    "    roster = roster.assign(teamnum = roster.team_abbreviated + roster['#'],\n",
    "                          Name = roster.Name.str.split('(').str[0].str.strip())\n",
    "\n",
    "    roster = roster.assign(Name = np.where((roster.Name=='SEBASTIAN AHO') &( roster.team_name == 'NEW YORK ISLANDERS'), 'SEBASTIAN AHO (SWE)', roster.Name))\n",
    "\n",
    "    goalies = roster[(roster.Pos=='G') & (roster.status!='scratch')]\n",
    "\n",
    "    away_roster = roster[(roster.team=='away') & (roster.status!='scratch')]\n",
    "    home_roster = roster[(roster.team=='home') & (roster.status!='scratch')]\n",
    "\n",
    "    merged.jumping_on = np.where(pd.isna(merged.jumping_on), '\\xa0', merged.jumping_on)\n",
    "    merged.jumping_off = np.where(pd.isna(merged.jumping_off), '\\xa0', merged.jumping_off)\n",
    "\n",
    "    awaydf = pd.DataFrame()\n",
    "\n",
    "    for i in range(0, len(away_roster)):\n",
    "        vec = pd.DataFrame(\n",
    "                np.cumsum(\n",
    "                    (np.where(merged.jumping_on.str.split(', ').apply(lambda x: away_roster.teamnum.iloc[i] in x)==True, 1, 0)) - (\n",
    "                    np.where((merged.jumping_off.str.split(', ').apply(lambda x: away_roster.teamnum.iloc[i] in x)==True) & (merged.event=='CHANGE'), 1, 0))\n",
    "                                     ))\n",
    "        awaydf = pd.concat([awaydf, vec], axis = 1)\n",
    "\n",
    "    awaydf.columns = away_roster.Name\n",
    "\n",
    "    global homedf\n",
    "\n",
    "    homedf = pd.DataFrame()\n",
    "\n",
    "    for i in range(0, len(home_roster)):\n",
    "        vec = pd.DataFrame(\n",
    "                np.cumsum(\n",
    "                    (np.where(merged.jumping_on.str.split(', ').apply(lambda x: home_roster.teamnum.iloc[i] in x)==True, 1, 0)) - (\n",
    "                    np.where((merged.jumping_off.str.split(', ').apply(lambda x: home_roster.teamnum.iloc[i] in x)==True) & (merged.event=='CHANGE'), 1, 0))\n",
    "                                     ))\n",
    "        homedf = pd.concat([homedf, vec], axis = 1)\n",
    "\n",
    "    homedf.columns = home_roster.Name\n",
    "\n",
    "    global home_on\n",
    "    global away_on\n",
    "\n",
    "    home_on = pd.DataFrame((homedf==1).apply(lambda y: homedf.columns[y.tolist()].tolist(), axis=1))\n",
    "    home_on[0] = (home_on[0].apply(','.join)).apply(lambda x: ','.join(natsorted(x.split(','))))\n",
    "\n",
    "    away_on = pd.DataFrame((awaydf==1).apply(lambda y: awaydf.columns[y.tolist()].tolist(), axis=1))\n",
    "    away_on[0] = (away_on[0].apply(','.join)).apply(lambda x: ','.join(natsorted(x.split(','))))\n",
    "\n",
    "    away_on = away_on[0].str.split(',', expand=True).rename(columns = {0:'away_on_1', 1:'away_on_2', 2:'away_on_3', 3:'away_on_4', 4:'away_on_5', 5:'away_on_6', 6:'away_on_7', 7:'away_on_8', 8:'away_on_9'})\n",
    "    home_on = home_on[0].str.split(',', expand=True).rename(columns = {0:'home_on_1', 1:'home_on_2', 2:'home_on_3', 3:'home_on_4', 4:'home_on_5', 5:'home_on_6', 6:'home_on_7', 7:'home_on_8', 8:'home_on_9'})\n",
    "\n",
    "    if 'away_on_6' not in away_on:\n",
    "        away_on['away_on_6'] = np.nan\n",
    "    if 'away_on_7' not in away_on:\n",
    "        away_on['away_on_7'] = np.nan\n",
    "    if 'away_on_8' not in away_on:\n",
    "        away_on['away_on_8'] = np.nan\n",
    "    if 'away_on_9' not in away_on:\n",
    "        away_on['away_on_9'] = np.nan\n",
    "    if 'home_on_6' not in home_on:\n",
    "        home_on['home_on_6'] = np.nan\n",
    "    if 'home_on_7' not in home_on:\n",
    "        home_on['home_on_7'] = np.nan\n",
    "    if 'home_on_8' not in home_on:\n",
    "        home_on['home_on_8'] = np.nan\n",
    "    if 'home_on_9' not in home_on:\n",
    "        home_on['home_on_9'] = np.nan\n",
    "\n",
    "    game = pd.concat([merged, home_on, away_on], axis = 1)\n",
    "\n",
    "    game = game.assign(\n",
    "    event_team = np.where(game.event_team==game.home_team, game.home_team_abbreviated,\n",
    "                         np.where(game.event_team==game.away_team, game.away_team_abbreviated,\n",
    "                                 game.event_team)),\n",
    "    description = game.description.astype(str))\n",
    "\n",
    "    game['description'] = np.where(game.description=='nan', '\\xa0', game.description)\n",
    "\n",
    "    game = game.drop(columns = ['original_index', 'strength', 'original_time', 'home_team', 'away_team', 'other_team', 'event_player_str',\n",
    "                                'version', 'team', 'change_before_event', 'prio', 'change_prio', 'priority', 'tmp', 'tmp2']).rename(\n",
    "        columns = {'away_team_abbreviated':'away_team', 'home_team_abbreviated':'home_team', 'coordsx':'coords_x', 'coordsy':'coords_y',\n",
    "                  'ep1_name':'event_player_1', 'ep2_name':'event_player_2', 'ep3_name':'event_player_3'}).assign(\n",
    "    game_id = int(game_id),\n",
    "    season = int(season),\n",
    "    event_zone = game.description.apply(lambda x: re.search('(\\S+?) Zone', x)).apply(lambda x: group_if_not_none(x)),\n",
    "    event_detail = \n",
    "           np.where(game.event.isin(['SHOT', 'BLOCK', 'MISS', 'GOAL']), \n",
    "                    game.description.str.split(', ').str[1].str.strip(),\n",
    "                        np.where(game.event.isin([\"PSTR\", \"PEND\", \"SOC\", \"GEND\"]),\n",
    "                        game.description.str.split(': ').str[1].str.strip(),\n",
    "                                np.where(game.event=='PENL', \n",
    "                                game.description.str.split('(').str[1].str.split(')').str[0].str.strip(),\n",
    "                                        np.where(game.event=='CHANGE',\n",
    "                                        game.description.str.split(' - ').str[0].str.strip(),\n",
    "                                            np.where(pd.isna(game.description), '\\xa0',\n",
    "                                                    '\\xa0'))))))\n",
    "\n",
    "    game = game.assign(home_goalie = np.where(\n",
    "    game.home_on_1.isin(goalies.Name), game.home_on_1,\n",
    "    np.where(\n",
    "    game.home_on_2.isin(goalies.Name), game.home_on_2,\n",
    "    np.where(\n",
    "    game.home_on_3.isin(goalies.Name), game.home_on_3,\n",
    "    np.where(\n",
    "    game.home_on_4.isin(goalies.Name), game.home_on_4,\n",
    "    np.where(\n",
    "    game.home_on_5.isin(goalies.Name), game.home_on_5,\n",
    "    np.where(\n",
    "    game.home_on_6.isin(goalies.Name), game.home_on_6,\n",
    "    np.where(\n",
    "    game.home_on_7.isin(goalies.Name), game.home_on_7,\n",
    "    np.where(\n",
    "    game.home_on_8.isin(goalies.Name), game.home_on_8,\n",
    "    np.where(\n",
    "    game.home_on_9.isin(goalies.Name), game.home_on_9,\n",
    "    np.nan))))))))),\n",
    "    away_goalie = np.where(\n",
    "    game.away_on_1.isin(goalies.Name), game.away_on_1,\n",
    "    np.where(\n",
    "    game.away_on_2.isin(goalies.Name), game.away_on_2,\n",
    "    np.where(\n",
    "    game.away_on_3.isin(goalies.Name), game.away_on_3,\n",
    "    np.where(\n",
    "    game.away_on_4.isin(goalies.Name), game.away_on_4,\n",
    "    np.where(\n",
    "    game.away_on_5.isin(goalies.Name), game.away_on_5,\n",
    "    np.where(\n",
    "    game.away_on_6.isin(goalies.Name), game.away_on_6,\n",
    "    np.where(\n",
    "    game.away_on_7.isin(goalies.Name), game.away_on_7,\n",
    "    np.where(\n",
    "    game.away_on_8.isin(goalies.Name), game.away_on_8,\n",
    "    np.where(\n",
    "    game.away_on_9.isin(goalies.Name), game.away_on_9,\n",
    "    np.nan))))))))))\n",
    "\n",
    "    game = game.assign(\n",
    "    away_on_1 = np.where((pd.isna(game.away_on_1)) | (game.away_on_1 is None) | (game.away_on_1=='') | (game.away_on_1=='\\xa0'), '\\xa0', game.away_on_1),\n",
    "    away_on_2 = np.where((pd.isna(game.away_on_2)) | (game.away_on_2 is None) | (game.away_on_2=='') | (game.away_on_2=='\\xa0'), '\\xa0', game.away_on_2),\n",
    "    away_on_3 = np.where((pd.isna(game.away_on_3)) | (game.away_on_3 is None) | (game.away_on_3=='') | (game.away_on_3=='\\xa0'), '\\xa0', game.away_on_3),\n",
    "    away_on_4 = np.where((pd.isna(game.away_on_4)) | (game.away_on_4 is None) | (game.away_on_4=='') | (game.away_on_4=='\\xa0'), '\\xa0', game.away_on_4),\n",
    "    away_on_5 = np.where((pd.isna(game.away_on_5)) | (game.away_on_5 is None) | (game.away_on_5=='') | (game.away_on_5=='\\xa0'), '\\xa0', game.away_on_5),\n",
    "    away_on_6 = np.where((pd.isna(game.away_on_6)) | (game.away_on_6 is None) | (game.away_on_6=='') | (game.away_on_6=='\\xa0'), '\\xa0', game.away_on_6),\n",
    "    away_on_7 = np.where((pd.isna(game.away_on_7)) | (game.away_on_7 is None) | (game.away_on_7=='') | (game.away_on_7=='\\xa0'), '\\xa0', game.away_on_7),\n",
    "    away_on_8 = np.where((pd.isna(game.away_on_8)) | (game.away_on_8 is None) | (game.away_on_8=='') | (game.away_on_8=='\\xa0'), '\\xa0', game.away_on_8),\n",
    "    away_on_9 = np.where((pd.isna(game.away_on_9)) | (game.away_on_9 is None) | (game.away_on_9=='') | (game.away_on_9=='\\xa0'), '\\xa0', game.away_on_9),\n",
    "    home_on_1 = np.where((pd.isna(game.home_on_1)) | (game.home_on_1 is None) | (game.home_on_1=='') | (game.home_on_1=='\\xa0'), '\\xa0', game.home_on_1),\n",
    "    home_on_2 = np.where((pd.isna(game.home_on_2)) | (game.home_on_2 is None) | (game.home_on_2=='') | (game.home_on_2=='\\xa0'), '\\xa0', game.home_on_2),\n",
    "    home_on_3 = np.where((pd.isna(game.home_on_3)) | (game.home_on_3 is None) | (game.home_on_3=='') | (game.home_on_3=='\\xa0'), '\\xa0', game.home_on_3),\n",
    "    home_on_4 = np.where((pd.isna(game.home_on_4)) | (game.home_on_4 is None) | (game.home_on_4=='') | (game.home_on_4=='\\xa0'), '\\xa0', game.home_on_4),\n",
    "    home_on_5 = np.where((pd.isna(game.home_on_5)) | (game.home_on_5 is None) | (game.home_on_5=='') | (game.home_on_5=='\\xa0'), '\\xa0', game.home_on_5),\n",
    "    home_on_6 = np.where((pd.isna(game.home_on_6)) | (game.home_on_6 is None) | (game.home_on_6=='') | (game.home_on_6=='\\xa0'), '\\xa0', game.home_on_6),\n",
    "    home_on_7 = np.where((pd.isna(game.home_on_7)) | (game.home_on_7 is None) | (game.home_on_7=='') | (game.home_on_7=='\\xa0'), '\\xa0', game.home_on_7),\n",
    "    home_on_8 = np.where((pd.isna(game.home_on_8)) | (game.home_on_8 is None) | (game.home_on_8=='') | (game.home_on_8=='\\xa0'), '\\xa0', game.home_on_8),\n",
    "    home_on_9 = np.where((pd.isna(game.home_on_9)) | (game.home_on_9 is None) | (game.home_on_9=='') | (game.home_on_9=='\\xa0'), '\\xa0', game.home_on_9),\n",
    "    home_goalie = np.where(pd.isna(game.home_goalie), '\\xa0', game.home_goalie), away_goalie = np.where(pd.isna(game.away_goalie), '\\xa0', game.away_goalie)\n",
    "    )\n",
    "\n",
    "    game = game.assign(home_skaters = \n",
    "                       np.where(game.home_on_1!='\\xa0', 1, 0) + np.where(game.home_on_2!='\\xa0', 1, 0) + np.where(game.home_on_3!='\\xa0', 1, 0) + np.where(game.home_on_4!='\\xa0', 1, 0) + \n",
    "                       np.where(game.home_on_5!='\\xa0', 1, 0) + np.where(game.home_on_6!='\\xa0', 1, 0) + np.where(game.home_on_7!='\\xa0', 1, 0) + np.where(game.home_on_8!='\\xa0', 1, 0) +\n",
    "                       np.where(game.home_on_9!='\\xa0', 1, 0) - np.where((game.home_goalie!='\\xa0') & (game.period<5), 1, 0),\n",
    "                       away_skaters = \n",
    "                       np.where(game.away_on_1!='\\xa0', 1, 0) + np.where(game.away_on_2!='\\xa0', 1, 0) + np.where(game.away_on_3!='\\xa0', 1, 0) + np.where(game.away_on_4!='\\xa0', 1, 0) + \n",
    "                       np.where(game.away_on_5!='\\xa0', 1, 0) + np.where(game.away_on_6!='\\xa0', 1, 0) + np.where(game.away_on_7!='\\xa0', 1, 0) + np.where(game.away_on_8!='\\xa0', 1, 0) +\n",
    "                       np.where(game.away_on_9!='\\xa0', 1, 0) - np.where((game.away_goalie!='\\xa0') & (game.period<5), 1, 0))\n",
    "\n",
    "    game = game.assign(home_skater_temp = \n",
    "                np.where((game.home_goalie=='\\xa0') , 'E', game.home_skaters),\n",
    "           away_skater_temp = \n",
    "                np.where((game.away_goalie=='\\xa0') , 'E', game.away_skaters))\n",
    "\n",
    "    game = game.assign(game_strength_state = (game.home_skater_temp.astype(str)) + 'v' + (game.away_skater_temp.astype(str)),\n",
    "                      event_zone = np.where(game.event_zone is not None, game.event_zone.str.replace(\". Zone\", \"\"), '\\xa0'),\n",
    "                      home_score = np.cumsum(np.where((game.event.shift()=='GOAL') & (game.period<5) & (game.event_team.shift()==game.home_team), 1, 0)),\n",
    "                      away_score = np.cumsum(np.where((game.event.shift()=='GOAL') & (game.period<5) & (game.event_team.shift()==game.away_team), 1, 0))).drop(\n",
    "        columns = ['home_skater_temp', 'away_skater_temp'])\n",
    "\n",
    "    game = game.assign(game_score_state = (game.home_score.astype(str)) + 'v' + (game.away_score.astype(str)),\n",
    "                      game_date = pd.to_datetime(game.game_date[~pd.isna(game.game_date)].iloc[0])\n",
    "                      )\n",
    "\n",
    "    game.number_off = np.where((game.jumping_on!='\\xa0') & (game.jumping_off=='\\xa0'), 0, game.number_off)\n",
    "    game.number_on = np.where((game.jumping_off!='\\xa0') & (game.jumping_on=='\\xa0'), 0, game.number_on)\n",
    "\n",
    "    so = game[game.period==5]\n",
    "\n",
    "    if len(so)>0:\n",
    "        game = game[game.period<5]\n",
    "        home = roster[roster.team=='home'].rename(columns = {'teamnum':'home_on_ice', 'Name':'home_goalie_name'}).loc[:, ['home_goalie_name', 'home_on_ice']]\n",
    "        away = roster[roster.team=='away'].rename(columns = {'teamnum':'away_on_ice', 'Name':'away_goalie_name'}).loc[:, ['away_goalie_name', 'away_on_ice']]\n",
    "        so = so.merge(away, how = 'left', indicator = True).drop(columns = ['_merge']).merge(home, how = 'left')\n",
    "        so = so.assign(\n",
    "        home_goalie = so.home_goalie_name,\n",
    "        away_goalie = so.away_goalie_name).drop(columns = ['away_goalie_name', 'home_goalie_name'])\n",
    "        so_winner = so[so.event=='GOAL'].groupby('event_team')['event', 'home_team'].count().reset_index().sort_values(by = ['event', 'event_team'],ascending = False).event_team.iloc[0]\n",
    "        so = so.assign(\n",
    "            home_on_1 = so.home_goalie,\n",
    "            away_on_1 = so.away_goalie,\n",
    "            home_on_2 = np.where(so.event_team==so.home_team, so.event_player_1, '\\xa0'),\n",
    "            away_on_2 = np.where(so.event_team==so.away_team, so.event_player_1, '\\xa0'))\n",
    "        if len(so[so.event=='PEND'])>0:\n",
    "            end_event = so[so.event=='PEND'].index.astype(int)[0]\n",
    "            so = so.assign(\n",
    "            home_score = np.where((so.index>=end_event) & (so_winner == so.home_team), 1+so.home_score, so.home_score),\n",
    "            away_score = np.where((so.index>=end_event) & (so_winner == so.away_team), 1+so.away_score, so.away_score))\n",
    "        game = pd.concat([game, so])\n",
    "\n",
    "    game['event_length'] = game.game_seconds.shift(-1) - game.game_seconds\n",
    "    game['event_length'] = (np.where((pd.isna(game.event_length)) | (game.event_length<0), 0, game.event_length)).astype(int)\n",
    "    game['event_index'] = game.event_index + 1\n",
    "    \n",
    "    if 'coords_x' and 'coords_y' in game.columns:\n",
    "    \n",
    "        columns = ['season', 'game_id', 'game_date', 'event_index',\n",
    "        'period', 'game_seconds', 'event', 'description',\n",
    "        'event_detail', 'event_zone', 'event_team', 'event_player_1',\n",
    "        'event_player_2', 'event_player_3', 'event_length', 'coords_x',\n",
    "        'coords_y', 'number_on', 'number_off', 'jumping_on', 'jumping_off',\n",
    "        'home_on_1', 'home_on_2', 'home_on_3', 'home_on_4', 'home_on_5',\n",
    "        'home_on_6', 'home_on_7', 'home_on_8', 'home_on_9', 'away_on_1', 'away_on_2', 'away_on_3',\n",
    "        'away_on_4', 'away_on_5', 'away_on_6', 'away_on_7', 'away_on_8', 'away_on_9', 'home_goalie',\n",
    "        'away_goalie', 'home_team', 'away_team', 'home_skaters', 'away_skaters',\n",
    "        'home_score', 'away_score', 'game_score_state', 'game_strength_state']\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        columns = ['season', 'game_id', 'game_date', 'event_index',\n",
    "        'period', 'game_seconds', 'event', 'description',\n",
    "        'event_detail', 'event_zone', 'event_team', 'event_player_1',\n",
    "        'event_player_2', 'event_player_3', 'event_length', \n",
    "        'number_on', 'number_off', 'jumping_on', 'jumping_off',\n",
    "        'home_on_1', 'home_on_2', 'home_on_3', 'home_on_4', 'home_on_5',\n",
    "        'home_on_6', 'home_on_7', 'home_on_8', 'home_on_9', 'away_on_1', 'away_on_2', 'away_on_3',\n",
    "        'away_on_4', 'away_on_5', 'away_on_6', 'away_on_7', 'away_on_8', 'away_on_9', 'home_goalie',\n",
    "        'away_goalie', 'home_team', 'away_team', 'home_skaters', 'away_skaters',\n",
    "        'home_score', 'away_score', 'game_score_state', 'game_strength_state']\n",
    "\n",
    "    game = game.loc[:, columns].rename(\n",
    "    columns = {'period':'game_period', 'event':'event_type', 'description':'event_description', 'number_on':'num_on', 'number_off':'num_off',\n",
    "              'jumping_on':'players_on', 'jumping_off':'players_off'}\n",
    "    )\n",
    "\n",
    "    return game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-updating",
   "metadata": {},
   "source": [
    "# FIX EVENTS WITH MISSING COORDINATES THAT CAN BE FIXED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "administrative-israeli",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_missing(single, event_coords, events):\n",
    "    \n",
    "    # FIRST FIX: EVENTS THAT HAVE MATCHING PERIOD, SECONDS, AND EVENT TYPE, AND ONLY OCCURRED ONCE, BUT NO EVENT PLAYER. #\n",
    "    global event_coords_temp\n",
    "    global single_problems\n",
    "    global merged_problems\n",
    "    problems = events[(events.event.isin(ewc)) & (pd.isna(events.coords_x))]\n",
    "    single_problems = problems.groupby(['event', 'period', 'game_seconds'])[\n",
    "        'event_index'].count().reset_index().rename(\n",
    "        columns = {'event_index':'problematic_events'})\n",
    "    # Keep events where only one event of that class happened at that moment.\n",
    "    single_problems = single_problems[single_problems.problematic_events==1]\n",
    "    single_problems = problems.merge(single_problems).drop(\n",
    "        columns = ['problematic_events', 'coords_x', 'coords_y']) # x/y come back later!\n",
    "    event_coords_temp = event_coords.loc[:, ['period', 'game_seconds', 'event', 'version', 'coords_x']].groupby(\n",
    "    ['game_seconds', 'period', 'event', 'version'])['coords_x'].count().reset_index().rename(\n",
    "        columns = {'coords_x':'problematic_events'})\n",
    "    event_coords_temp = event_coords_temp[event_coords_temp.problematic_events==1].drop(columns = 'problematic_events')\n",
    "    event_coords_temp = event_coords_temp.merge(event_coords.loc[:, ['game_seconds', 'period', 'event', 'version', 'coords_x', 'coords_y']])\n",
    "    if 'espn_id' in event_coords_temp.columns:\n",
    "        event_coords_temp = event_coords_temp.drop(columns = 'espn_id')\n",
    "    merged_problems = single_problems.merge(event_coords_temp)\n",
    "    print(\"You fixed: \" + str(len(merged_problems)) + \" events!\")\n",
    "    events = events[~(events.event_index.isin(list(merged_problems.event_index)))]\n",
    "    events = pd.concat([events, merged_problems.loc[:, list(events.columns)]]).sort_values(by = ['event_index', 'period', 'game_seconds'])\n",
    "    #if len(merged_problems)>0:\n",
    "        #events = events[~events.event_index.isin(merged_problems.event_index)]\n",
    "        #events = pd.concat([events, merged_problems.loc[:, list(events.columns)]]).sort_values(by = ['event_index', 'period', 'game_seconds'])\n",
    "    look = events\n",
    "    \n",
    "    # SECOND FIX: EVENTS THAT HAVE MATCHING PERIOD, EVENT TYPE, AND PLAYER ONE, AND ONLY OCCURRED ONCE, BUT NO GAME SECONDS.\n",
    "    \n",
    "    problems = events[(events.event.isin(ewc)) & (pd.isna(events.coords_x))]\n",
    "    single_problems = problems.groupby(['event', 'period', 'event_player_1'])[\n",
    "        'event_index'].count().reset_index().rename(\n",
    "        columns = {'event_index':'problematic_events'})\n",
    "    # Keep events where only one event of that class happened at that moment.\n",
    "    single_problems = single_problems[single_problems.problematic_events==1]\n",
    "    single_problems = problems.merge(single_problems).drop(\n",
    "        columns = ['problematic_events', 'coords_x', 'coords_y']) # x/y come back later!\n",
    "    event_coords_temp = event_coords.loc[:, ['period', 'event_player_1', 'event', \n",
    "                                        'version', 'coords_x']].groupby(\n",
    "    ['event_player_1', 'period', 'event', 'version'])['coords_x'].count().reset_index().rename(\n",
    "        columns = {'coords_x':'problematic_events'})\n",
    "    event_coords_temp = event_coords_temp[event_coords_temp.problematic_events==1].drop(columns = 'problematic_events')\n",
    "    event_coords_temp = event_coords_temp.merge(event_coords.loc[:, ['event_player_1', 'period', 'event', 'version', 'coords_x', 'coords_y']])\n",
    "    merged_problems = single_problems.merge(event_coords_temp)\n",
    "    print(\"You fixed: \" + str(len(merged_problems)) + \" events!\")\n",
    "    events = events[~events.event_index.isin(merged_problems.event_index)]\n",
    "    events = pd.concat([events, merged_problems]).sort_values(by = ['event_index', 'period', 'game_seconds'])\n",
    "    \n",
    "    return events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-kernel",
   "metadata": {},
   "source": [
    "# FULL SCRAPE 1 BY 1 FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "artistic-retirement",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def full_scrape_1by1(game_id_list, shift_to_espn = False):\n",
    "    \n",
    "    global single\n",
    "    global event_coords\n",
    "    global full\n",
    "    global fixed_events\n",
    "    global events\n",
    "    \n",
    "    full = pd.DataFrame()\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while i in range(0, len(game_id_list)):\n",
    "       \n",
    "        # First thing to try: Scraping HTML events\n",
    "        \n",
    "        try:\n",
    "            first_time = time.time()\n",
    "            game_id = game_id_list[i]\n",
    "            print('Attemtping scrape for: ' + str(game_id))\n",
    "            season = str(int(str(game_id)[:4])) + str(int(str(game_id)[:4]) + 1)\n",
    "            small_id = str(game_id)[5:]\n",
    "            single = scrape_html_events(season, small_id)\n",
    "            single['game_id'] = int(game_id)\n",
    "            \n",
    "            # If all goes well with the HTML scrape:\n",
    "            \n",
    "            try:\n",
    "                event_coords = scrape_api_events(game_id, shift_to_espn = shift_to_espn)\n",
    "                api_coords = event_coords\n",
    "                if len(event_coords[(event_coords.event.isin(ewc)) & (pd.isna(event_coords.coords_x))]) > 0:\n",
    "                    raise ExpatError('Bad takes, dude!')\n",
    "                event_coords['game_id'] = int(game_id)\n",
    "                events = single.merge(event_coords, on = ['event_player_1', 'game_seconds', 'version', 'period', 'game_id', 'event'], how = 'left')\n",
    "                events['coordinate_source'] = 'api'\n",
    "                try:\n",
    "                    events = fix_missing(single, event_coords, events)\n",
    "                except IndexError as e:\n",
    "                    print('Issue when fixing problematic events. Here it is: ' + str(e))\n",
    "                    continue\n",
    "                try:\n",
    "                    shifts = scrape_html_shifts(season, small_id)\n",
    "                    finalized = merge_and_prepare(events, shifts)\n",
    "                    finalized['coordinate_source'] = 'api'\n",
    "                    full = full.append(finalized)\n",
    "                    second_time = time.time()\n",
    "                except IndexError as e:\n",
    "                    print('There was no shift data for this game. Error: ' + str(e))\n",
    "                    fixed_events = events\n",
    "                    fixed_events = fixed_events.rename(\n",
    "                    columns = {'period':'game_period', 'event':'event_type', 'away_team_abbreviated':'away_team', \n",
    "                              'home_team_abbreviated':'home_team', 'description':'event_description', 'home_team':'hometeamfull',\n",
    "                              'away_team':'awayteamfull'}\n",
    "                    ).drop(\n",
    "                    columns = ['original_time', 'other_team', 'strength', 'event_player_str', 'version', 'hometeamfull', 'awayteamfull']\n",
    "                    ).assign(game_warning = 'NO SHIFT DATA.')\n",
    "                    full = full.append(fixed_events)\n",
    "                print('Successfully scraped ' + str(game_id) + '. Coordinates sourced from the API.')\n",
    "                print(\"This game took \" + str(round(second_time - first_time, 2)) + \" seconds.\")\n",
    "                i = i + 1\n",
    "                \n",
    "                # If there is an issue with the API:\n",
    "                \n",
    "            except KeyError: \n",
    "                print('The API gave us trouble with: ' + str(game_id) + '. Let us try ESPN.')\n",
    "                \n",
    "                try:\n",
    "                    home_team = single['home_team'].iloc[0]\n",
    "                    away_team = single['away_team'].iloc[0]\n",
    "                    game_date = single['game_date'].iloc[0]\n",
    "                    try:\n",
    "                        espn_id = scrape_espn_ids_single_game(str(game_date.date()), home_team, away_team).espn_id.iloc[0]\n",
    "                        event_coords = scrape_espn_events(int(espn_id))\n",
    "                        events = single.merge(event_coords, on = ['event_player_1', 'game_seconds', 'period', 'version', 'event'], how = 'left').drop(columns = ['espn_id'])\n",
    "                        try:\n",
    "                            events = fix_missing(single, event_coords, events)\n",
    "                        except IndexError as e:\n",
    "                            print('Issue when fixing problematic events. Here it is: ' + str(e))\n",
    "                            continue\n",
    "                    except IndexError:\n",
    "                        print('This game does not have ESPN or API coordinates. You will get it anyway, though.')\n",
    "                        events = single\n",
    "                    try:\n",
    "                        shifts = scrape_html_shifts(season, small_id)\n",
    "                        finalized = merge_and_prepare(events, shifts)\n",
    "                        finalized['coordinate_source'] = 'espn'\n",
    "                        full = full.append(finalized)\n",
    "                        second_time = time.time()\n",
    "                    except IndexError as e:\n",
    "                        print('There was no shift data for this game. Error: ' + str(e))\n",
    "                        fixed_events = events\n",
    "                        fixed_events = fixed_events.rename(\n",
    "                        columns = {'period':'game_period', 'event':'event_type', 'away_team_abbreviated':'away_team', \n",
    "                                  'home_team_abbreviated':'home_team', 'description':'event_description', 'home_team':'hometeamfull',\n",
    "                                  'away_team':'awayteamfull'}\n",
    "                        ).drop(\n",
    "                        columns = ['original_time', 'other_team', 'strength', 'event_player_str', 'version', 'hometeamfull', 'awayteamfull']\n",
    "                        ).assign(game_warning = 'NO SHIFT DATA')\n",
    "                        fixed_events['coordinate_source'] = 'espn'\n",
    "                        full = full.append(fixed_events)\n",
    "                    second_time = time.time()\n",
    "                    # Fix this so it doesn't say sourced from ESPN if no coords.\n",
    "                    if single.equals(events):\n",
    "                        print(\"This game took \" + str(round(second_time - first_time, 2)) + \" seconds.\")\n",
    "                        i = i + 1\n",
    "                    else:\n",
    "                        print('Successfully scraped ' + str(game_id) + '. Coordinates sourced from ESPN.')\n",
    "                        print(\"This game took \" + str(round(second_time - first_time, 2)) + \" seconds.\")\n",
    "                        i = i + 1\n",
    "                    \n",
    "                    # If there are issues with ESPN\n",
    "                    \n",
    "                except KeyError as e:\n",
    "                    print('ESPN also had trouble scraping coordinates for: ' + str(game_id) + '. Looks like we will need to punt this one, unfortunately.')\n",
    "                    print('KeyError: ' + str(e))\n",
    "                    i = i + 1\n",
    "                    continue\n",
    "                except IndexError as e:\n",
    "                    print('ESPN also had trouble scraping coordinates for: ' + str(game_id) + '. Looks like we will need to punt this one, unfortunately.')\n",
    "                    print('IndexError: ' + str(e))\n",
    "                    i = i + 1\n",
    "                    continue\n",
    "                except TypeError as e:\n",
    "                    print('ESPN also had trouble scraping coordinates for: ' + str(game_id) + '. Looks like we will need to punt this one, unfortunately.')\n",
    "                    print('TypeError: ' + str(e))\n",
    "                    i = i + 1\n",
    "                    continue\n",
    "                except ExpatError as e:\n",
    "                    print('ESPN also had trouble scraping coordinates for: ' + str(game_id) + '. Looks like we will need to punt this one, unfortunately.')\n",
    "                    print('ExpatError: ' + str(e))\n",
    "                    i = i + 1\n",
    "                    continue\n",
    "                \n",
    "            except ExpatError:\n",
    "                print('There was a rare error with the API; numerous takeaways did not have location coordinates for: ' + str(game_id) + '. Let us try ESPN.')\n",
    "                \n",
    "                try:\n",
    "                    home_team = single['home_team'].iloc[0]\n",
    "                    away_team = single['away_team'].iloc[0]\n",
    "                    game_date = single['game_date'].iloc[0]\n",
    "                    try:\n",
    "                        espn_id = scrape_espn_ids_single_game(str(game_date.date()), home_team, away_team).espn_id.iloc[0]\n",
    "                        event_coords = scrape_espn_events(int(espn_id))\n",
    "                        duped_coords = api_coords.assign(source = 'api').merge(event_coords.drop(columns = 'espn_id'), on = ['game_seconds', 'event', 'period', 'version'], how = 'outer')\n",
    "                        duped_coords = duped_coords.assign(source = np.where(pd.isna(duped_coords.source), 'espn', duped_coords.source))\n",
    "                        duped_coords = duped_coords.assign(coords_x = np.where(pd.isna(duped_coords.coords_x_x), duped_coords.coords_x_y, duped_coords.coords_x_x),\n",
    "                                                          coords_y = np.where(pd.isna(duped_coords.coords_y_x), duped_coords.coords_y_y, duped_coords.coords_y_x),\n",
    "                                                          event_player_1 = duped_coords.event_player_1_x)\n",
    "                        duped_coords = duped_coords.loc[:, api_coords.columns]\n",
    "                        duped_coords = duped_coords[duped_coords.event.isin(['SHOT', 'HIT', 'BLOCK', 'MISS', 'GIVE', 'TAKE', 'GOAL', 'PENL', 'FAC'])]\n",
    "                        duped_coords = duped_coords[~duped_coords.duplicated()]\n",
    "                        event_coords = duped_coords\n",
    "                        events = single.merge(event_coords, on = ['event_player_1', 'game_seconds', 'period', 'version', 'event'], how = 'left')#.drop(columns = ['espn_id'])\n",
    "                        try:\n",
    "                            events = fix_missing(single, event_coords, events)\n",
    "                            events['coordinate_source'] = 'mix'\n",
    "                        except IndexError as e:\n",
    "                            print('Issue when fixing problematic events. Here it is: ' + str(e))\n",
    "                    except IndexError as e:\n",
    "                        if event_coords is not None:\n",
    "                            print('Okay, ESPN had issues. We will go back to the API for this one. Issue: ' + str(e))\n",
    "                            events = single.merge(event_coords, on = ['event_player_1', 'game_seconds', 'version', 'period', 'event'], how = 'left')\n",
    "                            try:\n",
    "                                events = fix_missing(single, event_coords, events)\n",
    "                            except IndexError as e:\n",
    "                                print('Issue when fixing problematic events. Here it is: ' + str(e))\n",
    "                        else:\n",
    "                            print('This game does not have ESPN or API coordinates. You will get it anyway, though. Issue: ' + str(e))\n",
    "                            events = single\n",
    "                            events['coordinate_source'] = 'none'\n",
    "                    try:\n",
    "                        shifts = scrape_html_shifts(season, small_id)\n",
    "                        finalized = merge_and_prepare(events, shifts)\n",
    "                        full = full.append(finalized)\n",
    "                        second_time = time.time()\n",
    "                    except IndexError as e:\n",
    "                        print('There was no shift data for this game. Error: ' + str(e))\n",
    "                        fixed_events = events\n",
    "                        fixed_events = fixed_events.rename(\n",
    "                        columns = {'period':'game_period', 'event':'event_type', 'away_team_abbreviated':'away_team', \n",
    "                                  'home_team_abbreviated':'home_team', 'description':'event_description', 'home_team':'hometeamfull',\n",
    "                                  'away_team':'awayteamfull'}\n",
    "                        ).drop(\n",
    "                        columns = ['original_time', 'other_team', 'strength', 'event_player_str', 'version', 'hometeamfull', 'awayteamfull']\n",
    "                        ).assign(game_warning = 'NO SHIFT DATA')\n",
    "                        full = full.append(fixed_events)\n",
    "                    second_time = time.time()\n",
    "                    # Fix this so it doesn't say sourced from ESPN if no coords.\n",
    "                    print('Successfully scraped ' + str(game_id) + '. Coordinates sourced from ESPN.')\n",
    "                    print(\"This game took \" + str(round(second_time - first_time, 2)) + \" seconds.\")\n",
    "                    i = i + 1\n",
    "                    \n",
    "                    # If there are issues with ESPN\n",
    "                    \n",
    "                except KeyError as e:\n",
    "                    print('ESPN also had trouble scraping coordinates for: ' + str(game_id) + '. Looks like we will need to punt this one, unfortunately.')\n",
    "                    print('KeyError: ' + str(e))\n",
    "                    i = i + 1\n",
    "                    continue\n",
    "                except IndexError as e:\n",
    "                    print('ESPN also had trouble scraping coordinates for: ' + str(game_id) + '. Looks like we will need to punt this one, unfortunately.')\n",
    "                    print('IndexError: ' + str(e))\n",
    "                    i = i + 1\n",
    "                    continue\n",
    "                except TypeError as e:\n",
    "                    print('ESPN also had trouble scraping coordinates for: ' + str(game_id) + '. Looks like we will need to punt this one, unfortunately.')\n",
    "                    print('TypeError: ' + str(e))\n",
    "                    i = i + 1\n",
    "                    continue\n",
    "                except ExpatError as e:\n",
    "                    print('ESPN also had trouble scraping coordinates for: ' + str(game_id) + '. Looks like we will need to punt this one, unfortunately.')\n",
    "                    print('ExpatError: ' + str(e))\n",
    "                    i = i + 1\n",
    "                    continue\n",
    "            \n",
    "        except ConnectionError:\n",
    "            print('Got a Connection Error, time to sleep.')\n",
    "            time.sleep(10)\n",
    "            continue\n",
    "            \n",
    "        except AttributeError as e:\n",
    "            print(str(game_id) + ' does not have an HTML report. Here is the error: ' + str(e))\n",
    "            i = i + 1\n",
    "            continue\n",
    "            \n",
    "        except IndexError as e:\n",
    "            print(str(game_id) + ' has an issue with the HTML Report. Here is the error: ' + str(e))\n",
    "            i = i + 1\n",
    "            continue\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(str(game_id) + ' has an issue with the HTML Report. Here is the error: ' + str(e))\n",
    "            i = i + 1\n",
    "            continue\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print('You manually interrupted the scrape. You will get to keep every game you have already completed scraping. Good bye.')\n",
    "            global hidden_patrick\n",
    "            hidden_patrick = 1\n",
    "            return full\n",
    "        \n",
    "    return full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-alaska",
   "metadata": {},
   "source": [
    "# USER-END FUNCTION: full_scrape\n",
    "\n",
    "# PROVIDE A LIST TO full_scrape, YOU WILL RECEIVE A DATAFRAME THAT INCLUDES EVERY GAME FROM YOUR LIST THAT WAS SUCCESSFULLY SCRAPED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "eight-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_scrape(game_id_list, shift = False):\n",
    "    \n",
    "    hidden_patrick = 0\n",
    "    \n",
    "    df = full_scrape_1by1(game_id_list, shift_to_espn = shift)\n",
    "    return df\n",
    "    \n",
    "    if hidden_patrick==0:\n",
    "        \n",
    "        gids = list(set(fix0910.game_id))\n",
    "        missing = [x for x in game_id_list if x not in gids]\n",
    "        print('You missed the following games: ' + str(missing))\n",
    "        print('Let us try scraping each of them one more time.')\n",
    "        retry = full_scrape_1by1(missing)\n",
    "        if retry is not None:\n",
    "            df = df.append(retry)\n",
    "            return df\n",
    "        else:\n",
    "            return df\n",
    "    \n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-conclusion",
   "metadata": {},
   "source": [
    "# EXAMPLE RUN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "matched-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this list ends at 2011020005\n",
    "\n",
    "target_games = list(range(2011020001, 2011020006))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "buried-calvin",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attemtping scrape for: 2011020001\n",
      "You fixed: 0 events!\n",
      "You fixed: 0 events!\n",
      "Successfully scraped 2011020001. Coordinates sourced from the API.\n",
      "This game took 4.96 seconds.\n",
      "Attemtping scrape for: 2011020002\n",
      "You fixed: 0 events!\n",
      "You fixed: 0 events!\n",
      "Successfully scraped 2011020002. Coordinates sourced from the API.\n",
      "This game took 5.06 seconds.\n",
      "Attemtping scrape for: 2011020003\n",
      "You fixed: 0 events!\n",
      "You fixed: 0 events!\n",
      "Successfully scraped 2011020003. Coordinates sourced from the API.\n",
      "This game took 5.55 seconds.\n",
      "Attemtping scrape for: 2011020004\n",
      "You fixed: 0 events!\n",
      "You fixed: 0 events!\n",
      "Successfully scraped 2011020004. Coordinates sourced from the API.\n",
      "This game took 5.32 seconds.\n",
      "Attemtping scrape for: 2011020005\n",
      "You fixed: 0 events!\n",
      "You fixed: 0 events!\n",
      "Successfully scraped 2011020005. Coordinates sourced from the API.\n",
      "This game took 6.07 seconds.\n"
     ]
    }
   ],
   "source": [
    "example_scrape_1011 = full_scrape(target_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-oxide",
   "metadata": {},
   "source": [
    "# Findings from comparing single games:\n",
    "\n",
    "- 09-10: ESPN Coords x are 1 higher, coords y 1 lower, except opening faceoff with x 1 higher and y 2 lower, also a play with exact same coords.\n",
    "- 10-11: ESPN Coords x are 1 higher, coords y 1 lower, except opening faceoff with coords x and coords y both 2 higher.\n",
    "- 11-12: ESPN Coords x are 1 higher, coords y 1 lower, except opening faceoff with coords x 2 higher and coords y 2 lower.\n",
    "- 2013: ESPN x coords are 1 higher and coords y are 1 lower.\n",
    "- 13-14: ESPN Coords x are 1 higher, coords y 1 lower, except opening faceoff with coords x 1 higher and coords y the same.\n",
    "- 14-15: ESPN Coords x are 1 higher, coords y 1 lower, except opening faceoff with coords x 2 higher and coords y the same.\n",
    "- 15-16: ESPN Coords x are 1 higher, coords y are 1 lower."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
